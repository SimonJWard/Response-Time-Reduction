{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d68f83",
   "metadata": {},
   "source": [
    "# Pretrain LSTM Network using Simulated Data\n",
    "### target is validation loss, best model is saved, architecture given by 'SimulatedPretrainedModelTuner.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7691bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -1.2856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 35s 225ms/step - loss: -1.2856 - val_loss: -1.9603\n",
      "Epoch 2/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -2.4027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 221ms/step - loss: -2.4027 - val_loss: -2.7423\n",
      "Epoch 3/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -2.9056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 220ms/step - loss: -2.9056 - val_loss: -3.2143\n",
      "Epoch 4/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -3.1930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 220ms/step - loss: -3.1930 - val_loss: -3.3652\n",
      "Epoch 5/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -3.4060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -3.4060 - val_loss: -3.5936\n",
      "Epoch 6/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -3.5213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -3.5213 - val_loss: -3.7293\n",
      "Epoch 7/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.6314 - val_loss: -3.7067\n",
      "Epoch 8/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -3.5995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -3.5995 - val_loss: -3.8897\n",
      "Epoch 9/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -3.5708 - val_loss: -3.7288\n",
      "Epoch 10/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.7780 - val_loss: -3.7647\n",
      "Epoch 11/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.6889 - val_loss: -3.7951\n",
      "Epoch 12/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.9149 - val_loss: -3.4662\n",
      "Epoch 13/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -3.9678 - val_loss: -3.7405\n",
      "Epoch 14/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.0485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 220ms/step - loss: -4.0485 - val_loss: -4.1569\n",
      "Epoch 15/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.8295 - val_loss: -3.9089\n",
      "Epoch 16/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.0528 - val_loss: -4.1513\n",
      "Epoch 17/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.8718 - val_loss: -4.1262\n",
      "Epoch 18/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -3.9363 - val_loss: -4.0498\n",
      "Epoch 19/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.1373 - val_loss: -4.0439\n",
      "Epoch 20/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.1525 - val_loss: 3.8767\n",
      "Epoch 21/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -3.8711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -3.8711 - val_loss: -4.1893\n",
      "Epoch 22/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.1333 - val_loss: -4.1467\n",
      "Epoch 23/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.2021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -4.2021 - val_loss: -4.2229\n",
      "Epoch 24/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.1638 - val_loss: -4.1924\n",
      "Epoch 25/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.0220 - val_loss: -3.7603\n",
      "Epoch 26/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -4.2942 - val_loss: -4.0685\n",
      "Epoch 27/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.2302 - val_loss: -3.8273\n",
      "Epoch 28/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.3341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 223ms/step - loss: -4.3341 - val_loss: -4.3156\n",
      "Epoch 29/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2768 - val_loss: -4.0625\n",
      "Epoch 30/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.3251 - val_loss: -3.1903\n",
      "Epoch 31/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.2669 - val_loss: -4.0205\n",
      "Epoch 32/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.6639 - val_loss: -4.1745\n",
      "Epoch 33/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.7830 - val_loss: -4.2356\n",
      "Epoch 34/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.9552 - val_loss: -4.0689\n",
      "Epoch 35/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -4.0606 - val_loss: -2.4403\n",
      "Epoch 36/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.0654 - val_loss: -3.2099\n",
      "Epoch 37/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.0180 - val_loss: -3.9505\n",
      "Epoch 38/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.0367 - val_loss: -4.2010\n",
      "Epoch 39/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.2757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 221ms/step - loss: -4.2757 - val_loss: -4.4940\n",
      "Epoch 40/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.1838 - val_loss: -4.4077\n",
      "Epoch 41/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2333 - val_loss: -4.4090\n",
      "Epoch 42/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2231 - val_loss: -4.3750\n",
      "Epoch 43/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.1833 - val_loss: -4.4731\n",
      "Epoch 44/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.8990 - val_loss: -4.3519\n",
      "Epoch 45/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.1447 - val_loss: -4.1284\n",
      "Epoch 46/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3041 - val_loss: -4.4126\n",
      "Epoch 47/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2382 - val_loss: -3.4391\n",
      "Epoch 48/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.2909 - val_loss: -2.4801\n",
      "Epoch 49/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3325 - val_loss: -4.2483\n",
      "Epoch 50/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.3744 - val_loss: -3.5772\n",
      "Epoch 51/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4444 - val_loss: -4.3394\n",
      "Epoch 52/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.2995 - val_loss: -3.8243\n",
      "Epoch 53/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.3688 - val_loss: -4.4457\n",
      "Epoch 54/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.3916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -4.3916 - val_loss: -4.4941\n",
      "Epoch 55/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.3677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -4.3677 - val_loss: -4.4970\n",
      "Epoch 56/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.5019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -4.5019 - val_loss: -4.5937\n",
      "Epoch 57/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5015 - val_loss: -3.7200\n",
      "Epoch 58/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4737 - val_loss: -4.4495\n",
      "Epoch 59/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -4.5327 - val_loss: -4.3529\n",
      "Epoch 60/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5608 - val_loss: -4.5238\n",
      "Epoch 61/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.9027 - val_loss: -4.3334\n",
      "Epoch 62/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2240 - val_loss: -4.4461\n",
      "Epoch 63/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.3248 - val_loss: -4.0499\n",
      "Epoch 64/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.2223 - val_loss: -4.5581\n",
      "Epoch 65/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.3520 - val_loss: -4.4941\n",
      "Epoch 66/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3673 - val_loss: -4.5263\n",
      "Epoch 67/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4124 - val_loss: -4.4752\n",
      "Epoch 68/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.4570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 223ms/step - loss: -4.4570 - val_loss: -4.7066\n",
      "Epoch 69/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.3443 - val_loss: -4.4302\n",
      "Epoch 70/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5057 - val_loss: -4.3126\n",
      "Epoch 71/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.4471 - val_loss: -4.6453\n",
      "Epoch 72/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4788 - val_loss: -3.3527\n",
      "Epoch 73/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5746 - val_loss: -4.6466\n",
      "Epoch 74/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.4932 - val_loss: -4.4144\n",
      "Epoch 75/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4615 - val_loss: -4.0878\n",
      "Epoch 76/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5492 - val_loss: -4.4360\n",
      "Epoch 77/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4400 - val_loss: -4.3566\n",
      "Epoch 78/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5551 - val_loss: -4.4752\n",
      "Epoch 79/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5712 - val_loss: -4.4733\n",
      "Epoch 80/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6145 - val_loss: -4.6387\n",
      "Epoch 81/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5636 - val_loss: -4.4308\n",
      "Epoch 82/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5844 - val_loss: -4.3875\n",
      "Epoch 83/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5362 - val_loss: -4.5126\n",
      "Epoch 84/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6432 - val_loss: -4.5192\n",
      "Epoch 85/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.5979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 224ms/step - loss: -4.5979 - val_loss: -4.7439\n",
      "Epoch 86/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -4.5753 - val_loss: -4.4491\n",
      "Epoch 87/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6305 - val_loss: -4.6968\n",
      "Epoch 88/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.5442 - val_loss: -4.5721\n",
      "Epoch 89/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6859 - val_loss: -4.2874\n",
      "Epoch 90/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -3.8585 - val_loss: -4.3433\n",
      "Epoch 91/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.3791 - val_loss: -4.6376\n",
      "Epoch 92/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.2976 - val_loss: -4.6679\n",
      "Epoch 93/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4451 - val_loss: -4.6460\n",
      "Epoch 94/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5574 - val_loss: -3.4797\n",
      "Epoch 95/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6173 - val_loss: -4.5184\n",
      "Epoch 96/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5643 - val_loss: -4.0459\n",
      "Epoch 97/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5898 - val_loss: -4.5942\n",
      "Epoch 98/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5554 - val_loss: -4.2846\n",
      "Epoch 99/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6196 - val_loss: -4.6423\n",
      "Epoch 100/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3972 - val_loss: -4.6270\n",
      "Epoch 101/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.4200 - val_loss: -4.6359\n",
      "Epoch 102/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.7087 - val_loss: -4.4115\n",
      "Epoch 103/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.5501 - val_loss: -4.6725\n",
      "Epoch 104/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4898 - val_loss: -3.7904\n",
      "Epoch 105/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6405 - val_loss: -4.6498\n",
      "Epoch 106/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.7094 - val_loss: -4.6122\n",
      "Epoch 107/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6460 - val_loss: -4.5875\n",
      "Epoch 108/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.6317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -4.6317 - val_loss: -4.7542\n",
      "Epoch 109/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.7303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.7303 - val_loss: -4.7570\n",
      "Epoch 110/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.4850 - val_loss: -4.4792\n",
      "Epoch 111/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5016 - val_loss: -4.4982\n",
      "Epoch 112/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6337 - val_loss: -4.6736\n",
      "Epoch 113/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6716 - val_loss: -4.3918\n",
      "Epoch 114/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6268 - val_loss: -4.6784\n",
      "Epoch 115/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6847 - val_loss: -4.6721\n",
      "Epoch 116/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6505 - val_loss: -4.4927\n",
      "Epoch 117/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6730 - val_loss: -4.6593\n",
      "Epoch 118/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7499 - val_loss: -4.6439\n",
      "Epoch 119/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6284 - val_loss: -4.7406\n",
      "Epoch 120/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.7760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 222ms/step - loss: -4.7760 - val_loss: -4.7946\n",
      "Epoch 121/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.7195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.7195 - val_loss: -4.8536\n",
      "Epoch 122/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.7504 - val_loss: -4.6783\n",
      "Epoch 123/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.7841 - val_loss: -2.1693\n",
      "Epoch 124/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7502 - val_loss: -4.7193\n",
      "Epoch 125/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6352 - val_loss: -4.5746\n",
      "Epoch 126/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7564 - val_loss: -4.5858\n",
      "Epoch 127/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7981 - val_loss: -4.8348\n",
      "Epoch 128/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7241 - val_loss: -3.8640\n",
      "Epoch 129/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2501 - val_loss: -4.1909\n",
      "Epoch 130/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -3.5733 - val_loss: -4.2152\n",
      "Epoch 131/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -3.4728 - val_loss: -4.5016\n",
      "Epoch 132/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.8584 - val_loss: -3.7452\n",
      "Epoch 133/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3550 - val_loss: -4.5826\n",
      "Epoch 134/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.3766 - val_loss: -4.6800\n",
      "Epoch 135/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.4879 - val_loss: -4.4696\n",
      "Epoch 136/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4165 - val_loss: -4.4838\n",
      "Epoch 137/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5508 - val_loss: -4.6584\n",
      "Epoch 138/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6643 - val_loss: -4.5239\n",
      "Epoch 139/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6115 - val_loss: -4.6830\n",
      "Epoch 140/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6227 - val_loss: -4.6777\n",
      "Epoch 141/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6493 - val_loss: -4.4868\n",
      "Epoch 142/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6922 - val_loss: -4.5863\n",
      "Epoch 143/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5999 - val_loss: -4.2847\n",
      "Epoch 144/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6811 - val_loss: -4.6639\n",
      "Epoch 145/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.5485 - val_loss: -4.5144\n",
      "Epoch 146/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.6710 - val_loss: -4.7616\n",
      "Epoch 147/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6942 - val_loss: -4.7044\n",
      "Epoch 148/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7086 - val_loss: -3.2772\n",
      "Epoch 149/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7286 - val_loss: -3.3933\n",
      "Epoch 150/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7333 - val_loss: -4.0297\n",
      "Epoch 151/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.9879 - val_loss: -4.5655\n",
      "Epoch 152/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.0382 - val_loss: -4.2450\n",
      "Epoch 153/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.1853 - val_loss: -3.8673\n",
      "Epoch 154/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.3522 - val_loss: -4.7027\n",
      "Epoch 155/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5344 - val_loss: -4.6844\n",
      "Epoch 156/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.4824 - val_loss: -4.6535\n",
      "Epoch 157/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.5380 - val_loss: -4.4337\n",
      "Epoch 158/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6597 - val_loss: -4.3731\n",
      "Epoch 159/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6636 - val_loss: -4.3861\n",
      "Epoch 160/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.1589 - val_loss: -4.2601\n",
      "Epoch 161/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6481 - val_loss: -4.8007\n",
      "Epoch 162/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6955 - val_loss: -4.2111\n",
      "Epoch 163/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.5734 - val_loss: -4.5179\n",
      "Epoch 164/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.7141 - val_loss: -4.3101\n",
      "Epoch 165/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.7074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -4.7074 - val_loss: -4.8658\n",
      "Epoch 166/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7237 - val_loss: -2.9502\n",
      "Epoch 167/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7361 - val_loss: -2.9254\n",
      "Epoch 168/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7364 - val_loss: -4.7705\n",
      "Epoch 169/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.4198 - val_loss: -4.4861\n",
      "Epoch 170/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7672 - val_loss: -4.6560\n",
      "Epoch 171/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7975 - val_loss: -4.7311\n",
      "Epoch 172/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7663 - val_loss: -4.5889\n",
      "Epoch 173/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6318 - val_loss: -4.7666\n",
      "Epoch 174/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.8017 - val_loss: -4.5624\n",
      "Epoch 175/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.7764 - val_loss: -4.7057\n",
      "Epoch 176/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.8473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.8473 - val_loss: -4.8887\n",
      "Epoch 177/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.6955 - val_loss: -4.7441\n",
      "Epoch 178/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 224ms/step - loss: -4.7935 - val_loss: -4.9262\n",
      "Epoch 179/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7436 - val_loss: -4.8334\n",
      "Epoch 180/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8811 - val_loss: -4.7036\n",
      "Epoch 181/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7628 - val_loss: -4.6410\n",
      "Epoch 182/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8357 - val_loss: -4.9198\n",
      "Epoch 183/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7540 - val_loss: -4.8115\n",
      "Epoch 184/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8614 - val_loss: -4.8867\n",
      "Epoch 185/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7785 - val_loss: -4.8118\n",
      "Epoch 186/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -4.7516 - val_loss: -4.7460\n",
      "Epoch 187/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8762 - val_loss: -4.8460\n",
      "Epoch 188/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8710 - val_loss: -4.4113\n",
      "Epoch 189/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8461 - val_loss: -4.8856\n",
      "Epoch 190/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7976 - val_loss: -4.1118\n",
      "Epoch 191/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8522 - val_loss: -4.7458\n",
      "Epoch 192/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.9062 - val_loss: -4.6622\n",
      "Epoch 193/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6892 - val_loss: -4.7095\n",
      "Epoch 194/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.8975 - val_loss: -4.8849\n",
      "Epoch 195/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8963 - val_loss: -4.8625\n",
      "Epoch 196/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9174 - val_loss: -4.6994\n",
      "Epoch 197/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7867 - val_loss: -4.7038\n",
      "Epoch 198/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8363 - val_loss: -4.8476\n",
      "Epoch 199/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9266 - val_loss: -4.7168\n",
      "Epoch 200/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8820 - val_loss: -4.8453\n",
      "Epoch 201/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9387 - val_loss: -4.2420\n",
      "Epoch 202/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9022 - val_loss: -4.7441\n",
      "Epoch 203/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9349 - val_loss: -4.6583\n",
      "Epoch 204/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8627 - val_loss: -3.2919\n",
      "Epoch 205/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8763 - val_loss: -4.7451\n",
      "Epoch 206/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.9598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.9598 - val_loss: -4.9422\n",
      "Epoch 207/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.8155 - val_loss: -4.9391\n",
      "Epoch 208/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8601 - val_loss: -4.2320\n",
      "Epoch 209/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8780 - val_loss: -4.7578\n",
      "Epoch 210/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7785 - val_loss: -4.5586\n",
      "Epoch 211/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8980 - val_loss: -4.2118\n",
      "Epoch 212/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9298 - val_loss: -3.9409\n",
      "Epoch 213/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9699 - val_loss: -0.8963\n",
      "Epoch 214/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4203 - val_loss: -4.2666\n",
      "Epoch 215/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9309 - val_loss: -4.3926\n",
      "Epoch 216/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.9208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.9208 - val_loss: -4.9457\n",
      "Epoch 217/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6438 - val_loss: -4.3368\n",
      "Epoch 218/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8297 - val_loss: -4.7988\n",
      "Epoch 219/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.9775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -4.9775 - val_loss: -5.0255\n",
      "Epoch 220/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8780 - val_loss: -4.8776\n",
      "Epoch 221/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7838 - val_loss: -3.6610\n",
      "Epoch 222/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9009 - val_loss: -4.7436\n",
      "Epoch 223/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.7690 - val_loss: -4.3641\n",
      "Epoch 224/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.9466 - val_loss: -4.8787\n",
      "Epoch 225/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6886 - val_loss: -4.6949\n",
      "Epoch 226/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9351 - val_loss: -3.8068\n",
      "Epoch 227/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8518 - val_loss: -4.8655\n",
      "Epoch 228/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6093 - val_loss: -4.7965\n",
      "Epoch 229/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8418 - val_loss: -4.2071\n",
      "Epoch 230/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0071 - val_loss: -4.5686\n",
      "Epoch 231/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9269 - val_loss: -3.1416\n",
      "Epoch 232/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8533 - val_loss: -4.7890\n",
      "Epoch 233/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0107 - val_loss: -3.7295\n",
      "Epoch 234/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9303 - val_loss: -4.7766\n",
      "Epoch 235/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.9739 - val_loss: -4.9152\n",
      "Epoch 236/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.4190 - val_loss: -4.7503\n",
      "Epoch 237/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.7764 - val_loss: -4.9961\n",
      "Epoch 238/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9732 - val_loss: -4.7423\n",
      "Epoch 239/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9165 - val_loss: -4.7807\n",
      "Epoch 240/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7167 - val_loss: -4.8249\n",
      "Epoch 241/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8662 - val_loss: -4.7553\n",
      "Epoch 242/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9204 - val_loss: -4.7270\n",
      "Epoch 243/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8563 - val_loss: -4.8543\n",
      "Epoch 244/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9598 - val_loss: -4.7652\n",
      "Epoch 245/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9504 - val_loss: -4.8223\n",
      "Epoch 246/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9140 - val_loss: -1.9844\n",
      "Epoch 247/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8875 - val_loss: -4.6105\n",
      "Epoch 248/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7006 - val_loss: -3.7443\n",
      "Epoch 249/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7996 - val_loss: -4.6585\n",
      "Epoch 250/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0214 - val_loss: -4.9922\n",
      "Epoch 251/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9844 - val_loss: -3.5583\n",
      "Epoch 252/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9517 - val_loss: -3.6292\n",
      "Epoch 253/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9643 - val_loss: -3.5742\n",
      "Epoch 254/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -4.9390 - val_loss: -4.2032\n",
      "Epoch 255/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.9928 - val_loss: -4.6530\n",
      "Epoch 256/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0183 - val_loss: -4.7875\n",
      "Epoch 257/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0267 - val_loss: -3.9991\n",
      "Epoch 258/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9283 - val_loss: -3.5016\n",
      "Epoch 259/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0113 - val_loss: 4.9541\n",
      "Epoch 260/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.5238 - val_loss: -4.8388\n",
      "Epoch 261/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0361 - val_loss: -4.3704\n",
      "Epoch 262/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9049 - val_loss: -4.9643\n",
      "Epoch 263/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0306 - val_loss: -4.8138\n",
      "Epoch 264/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9968 - val_loss: -4.6438\n",
      "Epoch 265/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0430 - val_loss: -4.6986\n",
      "Epoch 266/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0590 - val_loss: -4.0385\n",
      "Epoch 267/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -3.3853 - val_loss: -4.8270\n",
      "Epoch 268/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -3.9475 - val_loss: -4.7289\n",
      "Epoch 269/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.1309 - val_loss: -4.2276\n",
      "Epoch 270/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6822 - val_loss: -4.6083\n",
      "Epoch 271/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7466 - val_loss: -4.6820\n",
      "Epoch 272/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7901 - val_loss: -4.7522\n",
      "Epoch 273/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -4.8746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 227ms/step - loss: -4.8746 - val_loss: -5.0436\n",
      "Epoch 274/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7429 - val_loss: -4.7938\n",
      "Epoch 275/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9280 - val_loss: -4.8865\n",
      "Epoch 276/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.8234 - val_loss: -4.8146\n",
      "Epoch 277/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7937 - val_loss: -4.1126\n",
      "Epoch 278/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9730 - val_loss: -4.0837\n",
      "Epoch 279/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0213 - val_loss: -4.9463\n",
      "Epoch 280/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8639 - val_loss: -4.7719\n",
      "Epoch 281/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0038 - val_loss: -4.8463\n",
      "Epoch 282/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9287 - val_loss: -4.6852\n",
      "Epoch 283/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9947 - val_loss: -4.7341\n",
      "Epoch 284/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9313 - val_loss: -4.6562\n",
      "Epoch 285/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.0621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.0621 - val_loss: -5.0670\n",
      "Epoch 286/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9223 - val_loss: -4.6785\n",
      "Epoch 287/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0258 - val_loss: -3.9083\n",
      "Epoch 288/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0406 - val_loss: -3.4033\n",
      "Epoch 289/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8879 - val_loss: -4.8519\n",
      "Epoch 290/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0365 - val_loss: -4.0800\n",
      "Epoch 291/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8179 - val_loss: -4.6130\n",
      "Epoch 292/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9534 - val_loss: -4.7619\n",
      "Epoch 293/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9922 - val_loss: -4.7085\n",
      "Epoch 294/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9930 - val_loss: -4.8021\n",
      "Epoch 295/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0243 - val_loss: -4.8919\n",
      "Epoch 296/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0142 - val_loss: -5.0001\n",
      "Epoch 297/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9825 - val_loss: -4.9981\n",
      "Epoch 298/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0754 - val_loss: -4.5014\n",
      "Epoch 299/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0609 - val_loss: -4.8216\n",
      "Epoch 300/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0445 - val_loss: -4.8680\n",
      "Epoch 301/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0483 - val_loss: -4.7226\n",
      "Epoch 302/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0114 - val_loss: -4.7813\n",
      "Epoch 303/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0375 - val_loss: -4.4714\n",
      "Epoch 304/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0794 - val_loss: -4.9830\n",
      "Epoch 305/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -5.1124 - val_loss: -4.8481\n",
      "Epoch 306/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.0836 - val_loss: -4.7431\n",
      "Epoch 307/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0135 - val_loss: -4.7838\n",
      "Epoch 308/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8406 - val_loss: -4.6365\n",
      "Epoch 309/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0781 - val_loss: -4.8606\n",
      "Epoch 310/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0133 - val_loss: -5.0625\n",
      "Epoch 311/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0730 - val_loss: -4.7654\n",
      "Epoch 312/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0814 - val_loss: -3.8565\n",
      "Epoch 313/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.8539 - val_loss: -4.7717\n",
      "Epoch 314/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0798 - val_loss: -4.8984\n",
      "Epoch 315/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9549 - val_loss: -4.6047\n",
      "Epoch 316/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.0370 - val_loss: -4.7106\n",
      "Epoch 317/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0783 - val_loss: -4.9935\n",
      "Epoch 318/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.7188 - val_loss: -4.8296\n",
      "Epoch 319/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.4603 - val_loss: -4.8849\n",
      "Epoch 320/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7780 - val_loss: -4.6646\n",
      "Epoch 321/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8761 - val_loss: -4.8990\n",
      "Epoch 322/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8854 - val_loss: -3.5263\n",
      "Epoch 323/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9575 - val_loss: -4.9770\n",
      "Epoch 324/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9605 - val_loss: -4.9161\n",
      "Epoch 325/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9848 - val_loss: -3.6652\n",
      "Epoch 326/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.1133 - val_loss: -4.6051\n",
      "Epoch 327/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.2857 - val_loss: -4.8997\n",
      "Epoch 328/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -3.9678 - val_loss: -4.8280\n",
      "Epoch 329/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.2618 - val_loss: -3.8012\n",
      "Epoch 330/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.4152 - val_loss: -4.8841\n",
      "Epoch 331/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.5805 - val_loss: -4.8024\n",
      "Epoch 332/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.5672 - val_loss: -4.0170\n",
      "Epoch 333/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7176 - val_loss: -4.7718\n",
      "Epoch 334/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.3593 - val_loss: -4.7914\n",
      "Epoch 335/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6457 - val_loss: -4.4673\n",
      "Epoch 336/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6975 - val_loss: -4.8125\n",
      "Epoch 337/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7388 - val_loss: -4.4357\n",
      "Epoch 338/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.6947 - val_loss: -4.7904\n",
      "Epoch 339/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.7518 - val_loss: -4.8448\n",
      "Epoch 340/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8230 - val_loss: -4.8003\n",
      "Epoch 341/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.7261 - val_loss: -4.8062\n",
      "Epoch 342/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.6904 - val_loss: -4.8077\n",
      "Epoch 343/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.4911 - val_loss: -4.7185\n",
      "Epoch 344/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.8051 - val_loss: -4.6909\n",
      "Epoch 345/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8023 - val_loss: -4.7678\n",
      "Epoch 346/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0252 - val_loss: -3.6591\n",
      "Epoch 347/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0252 - val_loss: -4.9232\n",
      "Epoch 348/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9633 - val_loss: -4.8114\n",
      "Epoch 349/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0293 - val_loss: -4.9816\n",
      "Epoch 350/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0337 - val_loss: -4.7842\n",
      "Epoch 351/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0350 - val_loss: -5.0217\n",
      "Epoch 352/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9717 - val_loss: -4.9617\n",
      "Epoch 353/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9940 - val_loss: -4.6664\n",
      "Epoch 354/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0554 - val_loss: -4.5978\n",
      "Epoch 355/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0970 - val_loss: -4.6339\n",
      "Epoch 356/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0370 - val_loss: -4.7139\n",
      "Epoch 357/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0106 - val_loss: -3.6523\n",
      "Epoch 358/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.5606 - val_loss: -4.7818\n",
      "Epoch 359/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7891 - val_loss: -4.8871\n",
      "Epoch 360/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9762 - val_loss: -4.6070\n",
      "Epoch 361/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9726 - val_loss: -4.9409\n",
      "Epoch 362/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0858 - val_loss: -4.3928\n",
      "Epoch 363/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0813 - val_loss: -4.8755\n",
      "Epoch 364/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0588 - val_loss: -4.8919\n",
      "Epoch 365/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9471 - val_loss: -4.8304\n",
      "Epoch 366/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6418 - val_loss: -4.8926\n",
      "Epoch 367/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9486 - val_loss: -4.9838\n",
      "Epoch 368/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0195 - val_loss: -4.9953\n",
      "Epoch 369/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -5.0839 - val_loss: -4.5350\n",
      "Epoch 370/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.4119 - val_loss: -2.8480\n",
      "Epoch 371/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.7528 - val_loss: -4.9666\n",
      "Epoch 372/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.0091 - val_loss: -4.9946\n",
      "Epoch 373/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0759 - val_loss: -4.9528\n",
      "Epoch 374/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9899 - val_loss: -4.5097\n",
      "Epoch 375/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.0238 - val_loss: -5.0369\n",
      "Epoch 376/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0391 - val_loss: -4.8107\n",
      "Epoch 377/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1504 - val_loss: -4.6679\n",
      "Epoch 378/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9065 - val_loss: -4.6661\n",
      "Epoch 379/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0620 - val_loss: -5.0387\n",
      "Epoch 380/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0868 - val_loss: -4.9955\n",
      "Epoch 381/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0090 - val_loss: -3.9214\n",
      "Epoch 382/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0072 - val_loss: -5.0310\n",
      "Epoch 383/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9974 - val_loss: -4.6822\n",
      "Epoch 384/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1101 - val_loss: -4.4623\n",
      "Epoch 385/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1213 - val_loss: -4.7784\n",
      "Epoch 386/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0653 - val_loss: -4.4932\n",
      "Epoch 387/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1547 - val_loss: -4.8364\n",
      "Epoch 388/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0515 - val_loss: -4.6694\n",
      "Epoch 389/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0286 - val_loss: -4.4759\n",
      "Epoch 390/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9326 - val_loss: -4.9560\n",
      "Epoch 391/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0985 - val_loss: -4.7523\n",
      "Epoch 392/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1179 - val_loss: -3.9942\n",
      "Epoch 393/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0551 - val_loss: -4.8047\n",
      "Epoch 394/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2181 - val_loss: -4.9444\n",
      "Epoch 395/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0730 - val_loss: -4.7246\n",
      "Epoch 396/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1533 - val_loss: -4.0259\n",
      "Epoch 397/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1780 - val_loss: -4.1335\n",
      "Epoch 398/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0966 - val_loss: -4.6118\n",
      "Epoch 399/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1231 - val_loss: -4.9318\n",
      "Epoch 400/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9879 - val_loss: -4.0027\n",
      "Epoch 401/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0900 - val_loss: -4.8694\n",
      "Epoch 402/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0529 - val_loss: -5.0309\n",
      "Epoch 403/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1849 - val_loss: -4.8222\n",
      "Epoch 404/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1028 - val_loss: -4.7299\n",
      "Epoch 405/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0851 - val_loss: -4.8836\n",
      "Epoch 406/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1008 - val_loss: -4.8595\n",
      "Epoch 407/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1267 - val_loss: -4.7107\n",
      "Epoch 408/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.1303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 31s 223ms/step - loss: -5.1303 - val_loss: -5.0702\n",
      "Epoch 409/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1905 - val_loss: -3.8308\n",
      "Epoch 410/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1816 - val_loss: -4.7454\n",
      "Epoch 411/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.2026 - val_loss: -5.0911\n",
      "Epoch 412/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0082 - val_loss: -4.7794\n",
      "Epoch 413/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.1104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 226ms/step - loss: -5.1104 - val_loss: -5.0946\n",
      "Epoch 414/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1921 - val_loss: -4.8960\n",
      "Epoch 415/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1123 - val_loss: -4.1851\n",
      "Epoch 416/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2049 - val_loss: -3.5265\n",
      "Epoch 417/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0932 - val_loss: -5.0017\n",
      "Epoch 418/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.1551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 227ms/step - loss: -5.1551 - val_loss: -5.1169\n",
      "Epoch 419/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1075 - val_loss: -5.0387\n",
      "Epoch 420/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1500 - val_loss: -4.2550\n",
      "Epoch 421/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0030 - val_loss: -4.7442\n",
      "Epoch 422/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1465 - val_loss: -4.9608\n",
      "Epoch 423/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1396 - val_loss: -5.0488\n",
      "Epoch 424/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1161 - val_loss: -4.9216\n",
      "Epoch 425/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0665 - val_loss: -4.8421\n",
      "Epoch 426/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1124 - val_loss: -5.1156\n",
      "Epoch 427/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1613 - val_loss: -4.7534\n",
      "Epoch 428/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1937 - val_loss: -4.7993\n",
      "Epoch 429/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -5.2008 - val_loss: -4.5499\n",
      "Epoch 430/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1083 - val_loss: -4.7171\n",
      "Epoch 431/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1588 - val_loss: -4.9941\n",
      "Epoch 432/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2190 - val_loss: -4.6972\n",
      "Epoch 433/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9759 - val_loss: -4.5427\n",
      "Epoch 434/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1216 - val_loss: -5.0003\n",
      "Epoch 435/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2074 - val_loss: -4.6278\n",
      "Epoch 436/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -5.2253 - val_loss: -5.1762\n",
      "Epoch 437/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2193 - val_loss: -4.6095\n",
      "Epoch 438/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1864 - val_loss: -5.0614\n",
      "Epoch 439/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1872 - val_loss: -2.2993\n",
      "Epoch 440/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1674 - val_loss: -4.1886\n",
      "Epoch 441/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2035 - val_loss: -4.9015\n",
      "Epoch 442/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2445 - val_loss: -5.1503\n",
      "Epoch 443/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2207 - val_loss: -4.6788\n",
      "Epoch 444/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0746 - val_loss: -5.0180\n",
      "Epoch 445/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2280 - val_loss: -3.9255\n",
      "Epoch 446/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1471 - val_loss: -4.9282\n",
      "Epoch 447/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2538 - val_loss: -4.9908\n",
      "Epoch 448/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2547 - val_loss: -3.6203\n",
      "Epoch 449/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2449 - val_loss: -4.8193\n",
      "Epoch 450/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1269 - val_loss: -5.0105\n",
      "Epoch 451/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2087 - val_loss: -5.0098\n",
      "Epoch 452/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2439 - val_loss: -4.5500\n",
      "Epoch 453/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1871 - val_loss: -4.8938\n",
      "Epoch 454/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2825 - val_loss: -4.3080\n",
      "Epoch 455/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2441 - val_loss: -4.8571\n",
      "Epoch 456/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1638 - val_loss: -5.0340\n",
      "Epoch 457/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2076 - val_loss: -4.9616\n",
      "Epoch 458/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1677 - val_loss: -4.9178\n",
      "Epoch 459/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2525 - val_loss: -3.2516\n",
      "Epoch 460/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2468 - val_loss: -4.9418\n",
      "Epoch 461/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1926 - val_loss: -3.6389\n",
      "Epoch 462/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1822 - val_loss: -4.7601\n",
      "Epoch 463/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1802 - val_loss: -5.0953\n",
      "Epoch 464/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1286 - val_loss: -4.7129\n",
      "Epoch 465/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3218 - val_loss: -4.4180\n",
      "Epoch 466/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2235 - val_loss: -4.8159\n",
      "Epoch 467/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1924 - val_loss: -5.1523\n",
      "Epoch 468/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2061 - val_loss: -4.8318\n",
      "Epoch 469/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2905 - val_loss: -4.8761\n",
      "Epoch 470/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2379 - val_loss: -2.2293\n",
      "Epoch 471/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1296 - val_loss: -4.3444\n",
      "Epoch 472/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1987 - val_loss: -5.0703\n",
      "Epoch 473/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -5.2337 - val_loss: -5.1763\n",
      "Epoch 474/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2060 - val_loss: -5.0190\n",
      "Epoch 475/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2659 - val_loss: -2.8052\n",
      "Epoch 476/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2055 - val_loss: -4.3461\n",
      "Epoch 477/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1886 - val_loss: -4.1003\n",
      "Epoch 478/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2331 - val_loss: -5.0607\n",
      "Epoch 479/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2609 - val_loss: -4.9404\n",
      "Epoch 480/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2376 - val_loss: -4.6755\n",
      "Epoch 481/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2573 - val_loss: -4.9161\n",
      "Epoch 482/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1281 - val_loss: -4.8434\n",
      "Epoch 483/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2368 - val_loss: -5.0434\n",
      "Epoch 484/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2746 - val_loss: -4.8490\n",
      "Epoch 485/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1916 - val_loss: -5.0921\n",
      "Epoch 486/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.0333 - val_loss: -4.8565\n",
      "Epoch 487/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1586 - val_loss: -4.8326\n",
      "Epoch 488/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1770 - val_loss: -5.1253\n",
      "Epoch 489/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1542 - val_loss: -5.0833\n",
      "Epoch 490/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2070 - val_loss: -4.5773\n",
      "Epoch 491/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2841 - val_loss: -4.3465\n",
      "Epoch 492/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2142 - val_loss: -5.0773\n",
      "Epoch 493/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2744 - val_loss: -5.1397\n",
      "Epoch 494/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2314 - val_loss: -5.0538\n",
      "Epoch 495/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1652 - val_loss: -4.9815\n",
      "Epoch 496/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2442 - val_loss: -5.1678\n",
      "Epoch 497/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2238 - val_loss: -5.1456\n",
      "Epoch 498/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1060 - val_loss: -4.9269\n",
      "Epoch 499/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -5.0739 - val_loss: -5.0457\n",
      "Epoch 500/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2853 - val_loss: -4.8390\n",
      "Epoch 501/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1630 - val_loss: -5.1251\n",
      "Epoch 502/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2255 - val_loss: -5.0218\n",
      "Epoch 503/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2888 - val_loss: -4.8652\n",
      "Epoch 504/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2215 - val_loss: -5.1471\n",
      "Epoch 505/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1347 - val_loss: -5.0141\n",
      "Epoch 506/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2356 - val_loss: -3.7949\n",
      "Epoch 507/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2598 - val_loss: -4.6617\n",
      "Epoch 508/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9976 - val_loss: -4.8696\n",
      "Epoch 509/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2468 - val_loss: -5.1239\n",
      "Epoch 510/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2928 - val_loss: -4.4724\n",
      "Epoch 511/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2212 - val_loss: -5.1284\n",
      "Epoch 512/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2970 - val_loss: -4.6223\n",
      "Epoch 513/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2439 - val_loss: -5.1636\n",
      "Epoch 514/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2038 - val_loss: -4.9643\n",
      "Epoch 515/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2526 - val_loss: -4.5237\n",
      "Epoch 516/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2678 - val_loss: -4.8153\n",
      "Epoch 517/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2470 - val_loss: -5.1515\n",
      "Epoch 518/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2716 - val_loss: -4.4784\n",
      "Epoch 519/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3053 - val_loss: -5.0689\n",
      "Epoch 520/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2581 - val_loss: -4.2641\n",
      "Epoch 521/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2428 - val_loss: -5.1617\n",
      "Epoch 522/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3843 - val_loss: -5.1395\n",
      "Epoch 523/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2366 - val_loss: -5.0823\n",
      "Epoch 524/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2106 - val_loss: -5.0422\n",
      "Epoch 525/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 226ms/step - loss: -5.2838 - val_loss: -5.2015\n",
      "Epoch 526/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0749 - val_loss: -5.0136\n",
      "Epoch 527/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2568 - val_loss: -3.7877\n",
      "Epoch 528/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2856 - val_loss: -4.1775\n",
      "Epoch 529/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1516 - val_loss: -4.8675\n",
      "Epoch 530/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 224ms/step - loss: -5.2984 - val_loss: -5.2284\n",
      "Epoch 531/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1926 - val_loss: -4.9911\n",
      "Epoch 532/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3013 - val_loss: -5.0592\n",
      "Epoch 533/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3392 - val_loss: -5.1804\n",
      "Epoch 534/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2124 - val_loss: -4.7985\n",
      "Epoch 535/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0338 - val_loss: -4.9010\n",
      "Epoch 536/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 227ms/step - loss: -5.2734 - val_loss: -5.2424\n",
      "Epoch 537/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1538 - val_loss: -3.5406\n",
      "Epoch 538/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2597 - val_loss: -4.4910\n",
      "Epoch 539/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2518 - val_loss: -4.8381\n",
      "Epoch 540/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2890 - val_loss: -5.0714\n",
      "Epoch 541/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1722 - val_loss: -4.2699\n",
      "Epoch 542/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3111 - val_loss: -3.0702\n",
      "Epoch 543/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2493 - val_loss: -4.9430\n",
      "Epoch 544/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2239 - val_loss: -4.8714\n",
      "Epoch 545/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2628 - val_loss: -5.0751\n",
      "Epoch 546/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1914 - val_loss: -4.0839\n",
      "Epoch 547/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3385 - val_loss: -4.9598\n",
      "Epoch 548/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2909 - val_loss: -4.4244\n",
      "Epoch 549/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3245 - val_loss: -4.9272\n",
      "Epoch 550/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2856 - val_loss: -5.1299\n",
      "Epoch 551/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3555 - val_loss: -4.6166\n",
      "Epoch 552/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2692 - val_loss: -4.9686\n",
      "Epoch 553/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1659 - val_loss: -5.2415\n",
      "Epoch 554/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3260 - val_loss: -4.8983\n",
      "Epoch 555/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2648 - val_loss: -4.7433\n",
      "Epoch 556/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3046 - val_loss: -3.7989\n",
      "Epoch 557/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2641 - val_loss: -4.8237\n",
      "Epoch 558/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3672 - val_loss: -4.8292\n",
      "Epoch 559/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0749 - val_loss: -5.2381\n",
      "Epoch 560/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2732 - val_loss: -5.1097\n",
      "Epoch 561/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2595 - val_loss: -4.8469\n",
      "Epoch 562/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2059 - val_loss: -4.3581\n",
      "Epoch 563/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2712 - val_loss: -5.0535\n",
      "Epoch 564/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2424 - val_loss: -5.1144\n",
      "Epoch 565/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3463 - val_loss: -5.1906\n",
      "Epoch 566/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2822 - val_loss: -4.9443\n",
      "Epoch 567/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3253 - val_loss: -5.2044\n",
      "Epoch 568/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2897 - val_loss: -5.1655\n",
      "Epoch 569/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2156 - val_loss: -5.0226\n",
      "Epoch 570/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2563 - val_loss: -4.7218\n",
      "Epoch 571/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3512 - val_loss: -4.6542\n",
      "Epoch 572/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3116 - val_loss: -4.9760\n",
      "Epoch 573/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.4326 - val_loss: -4.4740\n",
      "Epoch 574/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0028 - val_loss: -4.6981\n",
      "Epoch 575/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0771 - val_loss: -4.4582\n",
      "Epoch 576/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1862 - val_loss: -5.1835\n",
      "Epoch 577/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1556 - val_loss: -4.9841\n",
      "Epoch 578/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0576 - val_loss: -4.9492\n",
      "Epoch 579/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0056 - val_loss: -4.9217\n",
      "Epoch 580/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2316 - val_loss: -4.3377\n",
      "Epoch 581/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1917 - val_loss: -4.8998\n",
      "Epoch 582/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9479 - val_loss: -4.9939\n",
      "Epoch 583/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9690 - val_loss: -4.9516\n",
      "Epoch 584/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2146 - val_loss: -5.0655\n",
      "Epoch 585/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2162 - val_loss: -4.3599\n",
      "Epoch 586/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0383 - val_loss: -5.1194\n",
      "Epoch 587/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2901 - val_loss: -5.0668\n",
      "Epoch 588/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2118 - val_loss: -5.1129\n",
      "Epoch 589/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.2768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 226ms/step - loss: -5.2768 - val_loss: -5.2843\n",
      "Epoch 590/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.2291 - val_loss: -4.5848\n",
      "Epoch 591/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2751 - val_loss: -5.1685\n",
      "Epoch 592/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3563 - val_loss: -4.7751\n",
      "Epoch 593/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1284 - val_loss: -4.9402\n",
      "Epoch 594/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0185 - val_loss: -4.7083\n",
      "Epoch 595/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2911 - val_loss: -4.2445\n",
      "Epoch 596/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1977 - val_loss: -4.4582\n",
      "Epoch 597/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2326 - val_loss: -5.2274\n",
      "Epoch 598/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2686 - val_loss: -2.3461\n",
      "Epoch 599/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1636 - val_loss: -4.9133\n",
      "Epoch 600/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3270 - val_loss: -5.1335\n",
      "Epoch 601/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9014 - val_loss: -4.8598\n",
      "Epoch 602/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3079 - val_loss: -5.0259\n",
      "Epoch 603/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2511 - val_loss: -2.6144\n",
      "Epoch 604/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.1902 - val_loss: -5.0388\n",
      "Epoch 605/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3353 - val_loss: -4.2941\n",
      "Epoch 606/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.1967 - val_loss: -4.9216\n",
      "Epoch 607/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.3049 - val_loss: -5.0152\n",
      "Epoch 608/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.5921 - val_loss: -4.5203\n",
      "Epoch 609/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9495 - val_loss: -4.4260\n",
      "Epoch 610/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8704 - val_loss: -4.8780\n",
      "Epoch 611/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.6912 - val_loss: -4.3462\n",
      "Epoch 612/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9762 - val_loss: -5.1099\n",
      "Epoch 613/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0816 - val_loss: -4.7349\n",
      "Epoch 614/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0867 - val_loss: -4.0187\n",
      "Epoch 615/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0063 - val_loss: -5.0550\n",
      "Epoch 616/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0184 - val_loss: -5.0079\n",
      "Epoch 617/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0929 - val_loss: -4.8620\n",
      "Epoch 618/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0577 - val_loss: -4.8223\n",
      "Epoch 619/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.1694 - val_loss: -5.0115\n",
      "Epoch 620/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1622 - val_loss: -4.4851\n",
      "Epoch 621/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0224 - val_loss: -4.5800\n",
      "Epoch 622/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1413 - val_loss: -5.0865\n",
      "Epoch 623/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1191 - val_loss: -5.1968\n",
      "Epoch 624/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1997 - val_loss: -5.0714\n",
      "Epoch 625/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8629 - val_loss: -4.9727\n",
      "Epoch 626/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1495 - val_loss: -4.3584\n",
      "Epoch 627/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2219 - val_loss: -5.0629\n",
      "Epoch 628/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1508 - val_loss: -5.1079\n",
      "Epoch 629/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1839 - val_loss: -5.2262\n",
      "Epoch 630/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2015 - val_loss: -4.0511\n",
      "Epoch 631/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2630 - val_loss: -5.0835\n",
      "Epoch 632/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1158 - val_loss: -4.2759\n",
      "Epoch 633/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9734 - val_loss: -5.2038\n",
      "Epoch 634/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0978 - val_loss: -5.1055\n",
      "Epoch 635/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2145 - val_loss: -4.0113\n",
      "Epoch 636/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0998 - val_loss: -4.3341\n",
      "Epoch 637/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0534 - val_loss: -4.7938\n",
      "Epoch 638/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2956 - val_loss: -3.7489\n",
      "Epoch 639/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1110 - val_loss: -2.9954\n",
      "Epoch 640/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1733 - val_loss: -5.1288\n",
      "Epoch 641/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2144 - val_loss: -5.2327\n",
      "Epoch 642/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3279 - val_loss: -5.2518\n",
      "Epoch 643/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1066 - val_loss: -4.3571\n",
      "Epoch 644/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0955 - val_loss: -4.5809\n",
      "Epoch 645/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1494 - val_loss: -4.9370\n",
      "Epoch 646/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2874 - val_loss: -5.1985\n",
      "Epoch 647/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2963 - val_loss: -5.2311\n",
      "Epoch 648/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2108 - val_loss: -5.1272\n",
      "Epoch 649/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3320 - val_loss: -4.7890\n",
      "Epoch 650/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2400 - val_loss: -5.1552\n",
      "Epoch 651/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3808 - val_loss: -4.6245\n",
      "Epoch 652/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1957 - val_loss: -5.0487\n",
      "Epoch 653/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2918 - val_loss: -4.8048\n",
      "Epoch 654/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1939 - val_loss: -5.0648\n",
      "Epoch 655/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2659 - val_loss: -4.2287\n",
      "Epoch 656/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3076 - val_loss: -4.9308\n",
      "Epoch 657/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2427 - val_loss: -4.9663\n",
      "Epoch 658/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4005 - val_loss: -5.0239\n",
      "Epoch 659/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2604 - val_loss: -4.9809\n",
      "Epoch 660/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3369 - val_loss: -5.1460\n",
      "Epoch 661/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2745 - val_loss: -5.0247\n",
      "Epoch 662/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2453 - val_loss: -5.0313\n",
      "Epoch 663/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2534 - val_loss: -5.0994\n",
      "Epoch 664/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2578 - val_loss: -4.9497\n",
      "Epoch 665/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2658 - val_loss: -4.8561\n",
      "Epoch 666/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3778 - val_loss: -5.1813\n",
      "Epoch 667/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1099 - val_loss: -4.8442\n",
      "Epoch 668/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2198 - val_loss: -4.6139\n",
      "Epoch 669/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3769 - val_loss: -4.1705\n",
      "Epoch 670/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2834 - val_loss: -5.0786\n",
      "Epoch 671/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.3497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.3497 - val_loss: -5.3037\n",
      "Epoch 672/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0500 - val_loss: -4.5178\n",
      "Epoch 673/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0682 - val_loss: -5.0059\n",
      "Epoch 674/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1279 - val_loss: -4.5517\n",
      "Epoch 675/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1941 - val_loss: -5.0293\n",
      "Epoch 676/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1331 - val_loss: -5.1335\n",
      "Epoch 677/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3515 - val_loss: -5.1287\n",
      "Epoch 678/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2977 - val_loss: -5.0475\n",
      "Epoch 679/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2760 - val_loss: -5.2251\n",
      "Epoch 680/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2833 - val_loss: -4.6446\n",
      "Epoch 681/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3135 - val_loss: -4.9928\n",
      "Epoch 682/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4085 - val_loss: -5.1434\n",
      "Epoch 683/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3117 - val_loss: -4.8359\n",
      "Epoch 684/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3214 - val_loss: -5.1442\n",
      "Epoch 685/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1698 - val_loss: -5.2551\n",
      "Epoch 686/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2615 - val_loss: -4.9731\n",
      "Epoch 687/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2867 - val_loss: -4.9003\n",
      "Epoch 688/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.1925 - val_loss: -4.9329\n",
      "Epoch 689/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2655 - val_loss: -4.6984\n",
      "Epoch 690/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3189 - val_loss: -5.2730\n",
      "Epoch 691/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2919 - val_loss: -4.6378\n",
      "Epoch 692/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2783 - val_loss: -4.8164\n",
      "Epoch 693/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2840 - val_loss: -5.2107\n",
      "Epoch 694/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3073 - val_loss: -4.9434\n",
      "Epoch 695/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3945 - val_loss: -4.7668\n",
      "Epoch 696/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2785 - val_loss: -5.0658\n",
      "Epoch 697/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3637 - val_loss: -4.4795\n",
      "Epoch 698/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3083 - val_loss: -3.1169\n",
      "Epoch 699/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3762 - val_loss: -3.2967\n",
      "Epoch 700/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0987 - val_loss: -4.7493\n",
      "Epoch 701/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2484 - val_loss: -5.0426\n",
      "Epoch 702/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0204 - val_loss: -4.8617\n",
      "Epoch 703/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3013 - val_loss: -5.0674\n",
      "Epoch 704/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4241 - val_loss: -4.8812\n",
      "Epoch 705/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3522 - val_loss: -5.2624\n",
      "Epoch 706/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2568 - val_loss: -4.5747\n",
      "Epoch 707/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3243 - val_loss: -4.4714\n",
      "Epoch 708/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2796 - val_loss: -5.1033\n",
      "Epoch 709/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3136 - val_loss: -5.1060\n",
      "Epoch 710/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7829 - val_loss: -4.7645\n",
      "Epoch 711/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9327 - val_loss: -4.2715\n",
      "Epoch 712/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2597 - val_loss: -5.1720\n",
      "Epoch 713/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2499 - val_loss: -4.5055\n",
      "Epoch 714/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1647 - val_loss: -5.0935\n",
      "Epoch 715/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2685 - val_loss: -5.1696\n",
      "Epoch 716/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2204 - val_loss: -5.0446\n",
      "Epoch 717/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3270 - val_loss: -4.6749\n",
      "Epoch 718/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2948 - val_loss: -5.0374\n",
      "Epoch 719/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2963 - val_loss: -5.2072\n",
      "Epoch 720/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2464 - val_loss: -5.1466\n",
      "Epoch 721/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3144 - val_loss: -5.0437\n",
      "Epoch 722/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2933 - val_loss: -5.1948\n",
      "Epoch 723/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2683 - val_loss: -4.6981\n",
      "Epoch 724/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2132 - val_loss: -4.6091\n",
      "Epoch 725/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3083 - val_loss: -5.0599\n",
      "Epoch 726/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2357 - val_loss: -5.1694\n",
      "Epoch 727/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3940 - val_loss: -4.9744\n",
      "Epoch 728/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2764 - val_loss: -4.2028\n",
      "Epoch 729/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3655 - val_loss: -4.4891\n",
      "Epoch 730/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2294 - val_loss: -5.0767\n",
      "Epoch 731/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3901 - val_loss: -3.6838\n",
      "Epoch 732/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2592 - val_loss: -4.9694\n",
      "Epoch 733/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3381 - val_loss: -4.9696\n",
      "Epoch 734/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2867 - val_loss: -3.9808\n",
      "Epoch 735/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3629 - val_loss: -5.1858\n",
      "Epoch 736/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2669 - val_loss: -5.1195\n",
      "Epoch 737/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3583 - val_loss: -3.9561\n",
      "Epoch 738/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4183 - val_loss: -5.0040\n",
      "Epoch 739/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3088 - val_loss: -3.5389\n",
      "Epoch 740/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2629 - val_loss: -4.8112\n",
      "Epoch 741/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2463 - val_loss: -4.8840\n",
      "Epoch 742/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3799 - val_loss: -5.2318\n",
      "Epoch 743/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3835 - val_loss: -5.1717\n",
      "Epoch 744/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2813 - val_loss: -5.0566\n",
      "Epoch 745/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2831 - val_loss: -4.9148\n",
      "Epoch 746/2000\n",
      "141/141 [==============================] - 24s 171ms/step - loss: -5.1590 - val_loss: -5.1357\n",
      "Epoch 747/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3068 - val_loss: -4.1203\n",
      "Epoch 748/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2256 - val_loss: -5.1227\n",
      "Epoch 749/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3611 - val_loss: -5.0500\n",
      "Epoch 750/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3605 - val_loss: -4.7055\n",
      "Epoch 751/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3573 - val_loss: -4.7680\n",
      "Epoch 752/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3482 - val_loss: -3.6333\n",
      "Epoch 753/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3945 - val_loss: -5.0798\n",
      "Epoch 754/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4142 - val_loss: -5.1996\n",
      "Epoch 755/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2245 - val_loss: -5.1271\n",
      "Epoch 756/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3464 - val_loss: -4.5809\n",
      "Epoch 757/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3399 - val_loss: -5.1491\n",
      "Epoch 758/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3727 - val_loss: -5.2308\n",
      "Epoch 759/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2244 - val_loss: -4.1123\n",
      "Epoch 760/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2085 - val_loss: -4.2264\n",
      "Epoch 761/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2782 - val_loss: -4.5536\n",
      "Epoch 762/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3146 - val_loss: -4.0957\n",
      "Epoch 763/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3231 - val_loss: -5.2825\n",
      "Epoch 764/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2763 - val_loss: -4.8416\n",
      "Epoch 765/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3304 - val_loss: -4.6224\n",
      "Epoch 766/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3249 - val_loss: -4.9435\n",
      "Epoch 767/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2846 - val_loss: -5.1235\n",
      "Epoch 768/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3652 - val_loss: -4.6889\n",
      "Epoch 769/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2706 - val_loss: -4.9808\n",
      "Epoch 770/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4030 - val_loss: -4.8563\n",
      "Epoch 771/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3668 - val_loss: -5.2796\n",
      "Epoch 772/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3316 - val_loss: -4.8736\n",
      "Epoch 773/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4533 - val_loss: -5.2644\n",
      "Epoch 774/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3247 - val_loss: -4.4872\n",
      "Epoch 775/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3813 - val_loss: -5.1620\n",
      "Epoch 776/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3762 - val_loss: -4.7631\n",
      "Epoch 777/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3408 - val_loss: -5.0191\n",
      "Epoch 778/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4222 - val_loss: -5.0602\n",
      "Epoch 779/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3175 - val_loss: -4.8219\n",
      "Epoch 780/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3989 - val_loss: -5.1821\n",
      "Epoch 781/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2213 - val_loss: -5.1738\n",
      "Epoch 782/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2540 - val_loss: -5.1393\n",
      "Epoch 783/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3999 - val_loss: -5.2632\n",
      "Epoch 784/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2746 - val_loss: -5.2018\n",
      "Epoch 785/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3677 - val_loss: -5.1647\n",
      "Epoch 786/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3733 - val_loss: -5.0227\n",
      "Epoch 787/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1905 - val_loss: -3.7692\n",
      "Epoch 788/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3795 - val_loss: -5.1393\n",
      "Epoch 789/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4078 - val_loss: -5.1916\n",
      "Epoch 790/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4011 - val_loss: -5.2392\n",
      "Epoch 791/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3965 - val_loss: -3.7445\n",
      "Epoch 792/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.2732 - val_loss: -5.2563\n",
      "Epoch 793/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4019 - val_loss: -5.0494\n",
      "Epoch 794/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.4330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.4330 - val_loss: -5.3337\n",
      "Epoch 795/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3167 - val_loss: -5.1626\n",
      "Epoch 796/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3912 - val_loss: -5.2127\n",
      "Epoch 797/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4630 - val_loss: -4.5346\n",
      "Epoch 798/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3485 - val_loss: -5.2650\n",
      "Epoch 799/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0109 - val_loss: -4.7811\n",
      "Epoch 800/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8598 - val_loss: -5.0141\n",
      "Epoch 801/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0316 - val_loss: -5.0462\n",
      "Epoch 802/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1776 - val_loss: -4.3457\n",
      "Epoch 803/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1373 - val_loss: -3.8006\n",
      "Epoch 804/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0349 - val_loss: -4.9104\n",
      "Epoch 805/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2302 - val_loss: -4.5311\n",
      "Epoch 806/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3407 - val_loss: -4.9151\n",
      "Epoch 807/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3919 - val_loss: -5.1233\n",
      "Epoch 808/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2200 - val_loss: -4.9131\n",
      "Epoch 809/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2717 - val_loss: -3.6339\n",
      "Epoch 810/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4098 - val_loss: -5.2690\n",
      "Epoch 811/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2351 - val_loss: -5.0253\n",
      "Epoch 812/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3190 - val_loss: -5.2570\n",
      "Epoch 813/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3363 - val_loss: -5.0682\n",
      "Epoch 814/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2592 - val_loss: -5.2984\n",
      "Epoch 815/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2839 - val_loss: -4.8480\n",
      "Epoch 816/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4215 - val_loss: -4.4297\n",
      "Epoch 817/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3668 - val_loss: -5.1695\n",
      "Epoch 818/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4127 - val_loss: -5.2160\n",
      "Epoch 819/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4165 - val_loss: -5.2632\n",
      "Epoch 820/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3193 - val_loss: -4.7965\n",
      "Epoch 821/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4001 - val_loss: -5.0433\n",
      "Epoch 822/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4187 - val_loss: -5.0215\n",
      "Epoch 823/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2759 - val_loss: -5.1648\n",
      "Epoch 824/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4150 - val_loss: -5.2640\n",
      "Epoch 825/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3244 - val_loss: -4.9061\n",
      "Epoch 826/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4400 - val_loss: -4.8060\n",
      "Epoch 827/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3971 - val_loss: -4.7976\n",
      "Epoch 828/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3269 - val_loss: -4.9141\n",
      "Epoch 829/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6749 - val_loss: -5.1052\n",
      "Epoch 830/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.0024 - val_loss: -4.4362\n",
      "Epoch 831/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.0823 - val_loss: -4.9564\n",
      "Epoch 832/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9564 - val_loss: -4.9142\n",
      "Epoch 833/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2194 - val_loss: -5.0365\n",
      "Epoch 834/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2095 - val_loss: -5.2322\n",
      "Epoch 835/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3075 - val_loss: -5.0645\n",
      "Epoch 836/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3159 - val_loss: -4.8764\n",
      "Epoch 837/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3060 - val_loss: -5.2298\n",
      "Epoch 838/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3492 - val_loss: -5.2614\n",
      "Epoch 839/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3313 - val_loss: -5.1500\n",
      "Epoch 840/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3614 - val_loss: -4.8813\n",
      "Epoch 841/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2793 - val_loss: -5.2392\n",
      "Epoch 842/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3232 - val_loss: -4.8749\n",
      "Epoch 843/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4204 - val_loss: -5.1510\n",
      "Epoch 844/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4207 - val_loss: -5.1793\n",
      "Epoch 845/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2616 - val_loss: -5.1922\n",
      "Epoch 846/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3031 - val_loss: -4.8023\n",
      "Epoch 847/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3668 - val_loss: -5.0029\n",
      "Epoch 848/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.0427 - val_loss: -4.8838\n",
      "Epoch 849/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.4206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.4206 - val_loss: -5.3721\n",
      "Epoch 850/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3457 - val_loss: -4.2012\n",
      "Epoch 851/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4211 - val_loss: -5.0953\n",
      "Epoch 852/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4140 - val_loss: -4.5338\n",
      "Epoch 853/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2824 - val_loss: -4.3618\n",
      "Epoch 854/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3799 - val_loss: -5.1866\n",
      "Epoch 855/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3348 - val_loss: -4.2818\n",
      "Epoch 856/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3635 - val_loss: -5.2315\n",
      "Epoch 857/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4398 - val_loss: -5.0513\n",
      "Epoch 858/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4257 - val_loss: -4.5628\n",
      "Epoch 859/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4475 - val_loss: -5.2250\n",
      "Epoch 860/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3403 - val_loss: -5.3000\n",
      "Epoch 861/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4194 - val_loss: -0.2398\n",
      "Epoch 862/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3142 - val_loss: -5.2034\n",
      "Epoch 863/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3894 - val_loss: -4.5653\n",
      "Epoch 864/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4524 - val_loss: -4.9571\n",
      "Epoch 865/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2737 - val_loss: -5.1545\n",
      "Epoch 866/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4348 - val_loss: -5.0222\n",
      "Epoch 867/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2595 - val_loss: -5.2538\n",
      "Epoch 868/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3810 - val_loss: -4.4778\n",
      "Epoch 869/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4131 - val_loss: -5.1428\n",
      "Epoch 870/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4176 - val_loss: -4.5373\n",
      "Epoch 871/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4450 - val_loss: -4.1021\n",
      "Epoch 872/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4459 - val_loss: -5.1289\n",
      "Epoch 873/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -3.9533 - val_loss: -4.4571\n",
      "Epoch 874/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.1793 - val_loss: -4.6257\n",
      "Epoch 875/2000\n",
      "141/141 [==============================] - 24s 170ms/step - loss: -4.4886 - val_loss: -4.5025\n",
      "Epoch 876/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.6348 - val_loss: -4.5898\n",
      "Epoch 877/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.7263 - val_loss: -4.6900\n",
      "Epoch 878/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.7069 - val_loss: -4.4796\n",
      "Epoch 879/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.7101 - val_loss: -4.6445\n",
      "Epoch 880/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.7185 - val_loss: -4.9782\n",
      "Epoch 881/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9124 - val_loss: -4.6503\n",
      "Epoch 882/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -4.9529 - val_loss: -4.5913\n",
      "Epoch 883/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8697 - val_loss: -5.0946\n",
      "Epoch 884/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -4.9980 - val_loss: -5.0365\n",
      "Epoch 885/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -4.9398 - val_loss: -4.6287\n",
      "Epoch 886/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2246 - val_loss: -5.2088\n",
      "Epoch 887/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1654 - val_loss: -5.1996\n",
      "Epoch 888/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2151 - val_loss: -4.8323\n",
      "Epoch 889/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.1822 - val_loss: -5.2117\n",
      "Epoch 890/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2205 - val_loss: -5.0543\n",
      "Epoch 891/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3279 - val_loss: -5.1665\n",
      "Epoch 892/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3129 - val_loss: -4.4361\n",
      "Epoch 893/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2726 - val_loss: -5.0585\n",
      "Epoch 894/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3227 - val_loss: -5.2241\n",
      "Epoch 895/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9941 - val_loss: -4.9932\n",
      "Epoch 896/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1251 - val_loss: -4.7739\n",
      "Epoch 897/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3020 - val_loss: -5.3017\n",
      "Epoch 898/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1206 - val_loss: -4.8526\n",
      "Epoch 899/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3309 - val_loss: -1.7889\n",
      "Epoch 900/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1677 - val_loss: -4.6829\n",
      "Epoch 901/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3436 - val_loss: -3.8967\n",
      "Epoch 902/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -3.9543 - val_loss: -4.7728\n",
      "Epoch 903/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.8877 - val_loss: -4.8982\n",
      "Epoch 904/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.0847 - val_loss: -4.3823\n",
      "Epoch 905/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1690 - val_loss: -5.2599\n",
      "Epoch 906/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1734 - val_loss: -2.9461\n",
      "Epoch 907/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3084 - val_loss: -4.4072\n",
      "Epoch 908/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2080 - val_loss: -5.2430\n",
      "Epoch 909/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1851 - val_loss: -5.2241\n",
      "Epoch 910/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2977 - val_loss: -4.5536\n",
      "Epoch 911/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2225 - val_loss: -5.2438\n",
      "Epoch 912/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2613 - val_loss: -4.9045\n",
      "Epoch 913/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9698 - val_loss: -5.1001\n",
      "Epoch 914/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2158 - val_loss: -5.2288\n",
      "Epoch 915/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3724 - val_loss: -4.4167\n",
      "Epoch 916/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2243 - val_loss: -5.1625\n",
      "Epoch 917/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2878 - val_loss: -5.1809\n",
      "Epoch 918/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1830 - val_loss: -4.6601\n",
      "Epoch 919/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3469 - val_loss: -4.9064\n",
      "Epoch 920/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3220 - val_loss: -4.6462\n",
      "Epoch 921/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2487 - val_loss: -5.1312\n",
      "Epoch 922/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2367 - val_loss: -4.4575\n",
      "Epoch 923/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3610 - val_loss: -4.7420\n",
      "Epoch 924/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2848 - val_loss: -4.6998\n",
      "Epoch 925/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1846 - val_loss: -4.8097\n",
      "Epoch 926/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3938 - val_loss: -4.9787\n",
      "Epoch 927/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3801 - val_loss: -5.0508\n",
      "Epoch 928/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3506 - val_loss: -5.0141\n",
      "Epoch 929/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1291 - val_loss: -4.8653\n",
      "Epoch 930/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3996 - val_loss: -5.2555\n",
      "Epoch 931/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2880 - val_loss: -5.0521\n",
      "Epoch 932/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3112 - val_loss: -5.2129\n",
      "Epoch 933/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3406 - val_loss: -4.1269\n",
      "Epoch 934/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2908 - val_loss: -5.1351\n",
      "Epoch 935/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3716 - val_loss: -5.3302\n",
      "Epoch 936/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3352 - val_loss: -4.7861\n",
      "Epoch 937/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3981 - val_loss: -5.2803\n",
      "Epoch 938/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2700 - val_loss: -5.1092\n",
      "Epoch 939/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4449 - val_loss: -5.2296\n",
      "Epoch 940/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3967 - val_loss: -3.9481\n",
      "Epoch 941/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2516 - val_loss: -5.1064\n",
      "Epoch 942/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3807 - val_loss: -5.2983\n",
      "Epoch 943/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4391 - val_loss: -4.0744\n",
      "Epoch 944/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.0792 - val_loss: -4.8862\n",
      "Epoch 945/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2266 - val_loss: -5.2220\n",
      "Epoch 946/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3840 - val_loss: -5.1178\n",
      "Epoch 947/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3973 - val_loss: -5.0337\n",
      "Epoch 948/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1797 - val_loss: -4.9516\n",
      "Epoch 949/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3606 - val_loss: -4.5129\n",
      "Epoch 950/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2424 - val_loss: -5.2045\n",
      "Epoch 951/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2880 - val_loss: -5.1283\n",
      "Epoch 952/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4598 - val_loss: -5.1955\n",
      "Epoch 953/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3683 - val_loss: -5.2375\n",
      "Epoch 954/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3460 - val_loss: -3.4684\n",
      "Epoch 955/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3294 - val_loss: -5.2754\n",
      "Epoch 956/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3895 - val_loss: -4.6934\n",
      "Epoch 957/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4760 - val_loss: -5.2438\n",
      "Epoch 958/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2589 - val_loss: -5.0425\n",
      "Epoch 959/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3765 - val_loss: -5.2198\n",
      "Epoch 960/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.4152 - val_loss: -5.1501\n",
      "Epoch 961/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4318 - val_loss: -4.8069\n",
      "Epoch 962/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3821 - val_loss: -5.1525\n",
      "Epoch 963/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3333 - val_loss: -5.3357\n",
      "Epoch 964/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3196 - val_loss: -4.5815\n",
      "Epoch 965/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3906 - val_loss: -3.8822\n",
      "Epoch 966/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1965 - val_loss: -5.1272\n",
      "Epoch 967/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1761 - val_loss: -5.1963\n",
      "Epoch 968/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3839 - val_loss: -5.2028\n",
      "Epoch 969/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3828 - val_loss: -5.2159\n",
      "Epoch 970/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3385 - val_loss: -3.8223\n",
      "Epoch 971/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3867 - val_loss: -5.1029\n",
      "Epoch 972/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.4081 - val_loss: -5.1339\n",
      "Epoch 973/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3649 - val_loss: -4.9040\n",
      "Epoch 974/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4234 - val_loss: -5.2655\n",
      "Epoch 975/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3274 - val_loss: -4.7449\n",
      "Epoch 976/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4392 - val_loss: -5.0911\n",
      "Epoch 977/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3770 - val_loss: -5.2631\n",
      "Epoch 978/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2744 - val_loss: -4.7934\n",
      "Epoch 979/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4056 - val_loss: -5.3082\n",
      "Epoch 980/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4203 - val_loss: -5.1499\n",
      "Epoch 981/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4119 - val_loss: -4.8568\n",
      "Epoch 982/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3909 - val_loss: -5.0108\n",
      "Epoch 983/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3993 - val_loss: -5.2128\n",
      "Epoch 984/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4486 - val_loss: -4.1170\n",
      "Epoch 985/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4196 - val_loss: -4.3502\n",
      "Epoch 986/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2148 - val_loss: -4.6289\n",
      "Epoch 987/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4832 - val_loss: -5.0760\n",
      "Epoch 988/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4507 - val_loss: -4.4336\n",
      "Epoch 989/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2949 - val_loss: -5.2065\n",
      "Epoch 990/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4123 - val_loss: -4.0133\n",
      "Epoch 991/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1680 - val_loss: -5.0893\n",
      "Epoch 992/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1928 - val_loss: -5.2918\n",
      "Epoch 993/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2544 - val_loss: -5.2736\n",
      "Epoch 994/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3407 - val_loss: -4.8093\n",
      "Epoch 995/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3755 - val_loss: -5.2562\n",
      "Epoch 996/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3449 - val_loss: -5.3036\n",
      "Epoch 997/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4143 - val_loss: -4.9539\n",
      "Epoch 998/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4716 - val_loss: -5.2248\n",
      "Epoch 999/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2854 - val_loss: -5.2292\n",
      "Epoch 1000/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4623 - val_loss: -5.2484\n",
      "Epoch 1001/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3410 - val_loss: -4.5894\n",
      "Epoch 1002/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4134 - val_loss: -4.3359\n",
      "Epoch 1003/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4458 - val_loss: -5.2869\n",
      "Epoch 1004/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3625 - val_loss: -5.0669\n",
      "Epoch 1005/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5005 - val_loss: -5.3260\n",
      "Epoch 1006/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2646 - val_loss: -5.2502\n",
      "Epoch 1007/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3751 - val_loss: -4.3700\n",
      "Epoch 1008/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3510 - val_loss: -5.1998\n",
      "Epoch 1009/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4928 - val_loss: -5.2579\n",
      "Epoch 1010/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3552 - val_loss: -5.0504\n",
      "Epoch 1011/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4499 - val_loss: -5.2844\n",
      "Epoch 1012/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3648 - val_loss: -5.2872\n",
      "Epoch 1013/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3606 - val_loss: -5.0430\n",
      "Epoch 1014/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4743 - val_loss: -5.1037\n",
      "Epoch 1015/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3862 - val_loss: -4.2886\n",
      "Epoch 1016/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3582 - val_loss: -4.7687\n",
      "Epoch 1017/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3756 - val_loss: -4.3805\n",
      "Epoch 1018/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3864 - val_loss: -5.2519\n",
      "Epoch 1019/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3505 - val_loss: -3.0782\n",
      "Epoch 1020/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3825 - val_loss: -5.2428\n",
      "Epoch 1021/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4483 - val_loss: -4.1856\n",
      "Epoch 1022/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4786 - val_loss: -5.1035\n",
      "Epoch 1023/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2931 - val_loss: -5.2638\n",
      "Epoch 1024/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4560 - val_loss: -4.4163\n",
      "Epoch 1025/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4059 - val_loss: -5.2419\n",
      "Epoch 1026/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4043 - val_loss: -4.3281\n",
      "Epoch 1027/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4338 - val_loss: -4.8150\n",
      "Epoch 1028/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3768 - val_loss: -4.6983\n",
      "Epoch 1029/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4305 - val_loss: -5.1064\n",
      "Epoch 1030/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3878 - val_loss: -5.1881\n",
      "Epoch 1031/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5020 - val_loss: -5.1755\n",
      "Epoch 1032/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4556 - val_loss: -4.4312\n",
      "Epoch 1033/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3519 - val_loss: -4.5624\n",
      "Epoch 1034/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3873 - val_loss: -4.4050\n",
      "Epoch 1035/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3759 - val_loss: -5.2012\n",
      "Epoch 1036/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4756 - val_loss: -5.2510\n",
      "Epoch 1037/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4864 - val_loss: -5.2977\n",
      "Epoch 1038/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4342 - val_loss: -4.7538\n",
      "Epoch 1039/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4579 - val_loss: -5.3354\n",
      "Epoch 1040/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4480 - val_loss: -5.2153\n",
      "Epoch 1041/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4460 - val_loss: -4.2798\n",
      "Epoch 1042/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3591 - val_loss: -4.8334\n",
      "Epoch 1043/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4500 - val_loss: -5.2669\n",
      "Epoch 1044/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4609 - val_loss: -5.3197\n",
      "Epoch 1045/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3461 - val_loss: -4.9654\n",
      "Epoch 1046/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4737 - val_loss: -4.8918\n",
      "Epoch 1047/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4930 - val_loss: -5.1961\n",
      "Epoch 1048/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4539 - val_loss: -5.1853\n",
      "Epoch 1049/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2519 - val_loss: -4.9684\n",
      "Epoch 1050/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4173 - val_loss: -4.5457\n",
      "Epoch 1051/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3814 - val_loss: -5.1203\n",
      "Epoch 1052/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4708 - val_loss: -5.0813\n",
      "Epoch 1053/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4749 - val_loss: -5.2196\n",
      "Epoch 1054/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2382 - val_loss: -5.0766\n",
      "Epoch 1055/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5337 - val_loss: -5.3203\n",
      "Epoch 1056/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4090 - val_loss: -4.9330\n",
      "Epoch 1057/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5228 - val_loss: -5.2075\n",
      "Epoch 1058/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3787 - val_loss: -4.7737\n",
      "Epoch 1059/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2702 - val_loss: -5.2660\n",
      "Epoch 1060/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4292 - val_loss: -5.0245\n",
      "Epoch 1061/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4659 - val_loss: -4.2872\n",
      "Epoch 1062/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4208 - val_loss: -3.9632\n",
      "Epoch 1063/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4103 - val_loss: -5.1149\n",
      "Epoch 1064/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4921 - val_loss: -5.3374\n",
      "Epoch 1065/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4052 - val_loss: -5.2906\n",
      "Epoch 1066/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3784 - val_loss: -4.6699\n",
      "Epoch 1067/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3596 - val_loss: -5.2294\n",
      "Epoch 1068/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5413 - val_loss: -5.2455\n",
      "Epoch 1069/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4475 - val_loss: -3.5461\n",
      "Epoch 1070/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4282 - val_loss: -2.5872\n",
      "Epoch 1071/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5122 - val_loss: -4.9505\n",
      "Epoch 1072/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4370 - val_loss: -5.3287\n",
      "Epoch 1073/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.1806 - val_loss: -4.3200\n",
      "Epoch 1074/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4516 - val_loss: -4.0046\n",
      "Epoch 1075/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.8995 - val_loss: -5.0256\n",
      "Epoch 1076/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2883 - val_loss: -4.9502\n",
      "Epoch 1077/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4389 - val_loss: -4.8873\n",
      "Epoch 1078/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3145 - val_loss: -5.0245\n",
      "Epoch 1079/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4729 - val_loss: -4.8990\n",
      "Epoch 1080/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3251 - val_loss: -5.0443\n",
      "Epoch 1081/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3886 - val_loss: -5.2784\n",
      "Epoch 1082/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4675 - val_loss: -4.2737\n",
      "Epoch 1083/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3265 - val_loss: -5.2336\n",
      "Epoch 1084/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4574 - val_loss: -4.8015\n",
      "Epoch 1085/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4538 - val_loss: -5.2009\n",
      "Epoch 1086/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4126 - val_loss: -4.9294\n",
      "Epoch 1087/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4401 - val_loss: -5.2098\n",
      "Epoch 1088/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4872 - val_loss: -4.7103\n",
      "Epoch 1089/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3649 - val_loss: -4.7689\n",
      "Epoch 1090/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3658 - val_loss: -4.1063\n",
      "Epoch 1091/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4260 - val_loss: -5.1047\n",
      "Epoch 1092/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4724 - val_loss: -5.2646\n",
      "Epoch 1093/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4545 - val_loss: -4.7289\n",
      "Epoch 1094/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.6177 - val_loss: -5.0029\n",
      "Epoch 1095/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2047 - val_loss: -5.2780\n",
      "Epoch 1096/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2474 - val_loss: -5.1851\n",
      "Epoch 1097/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3363 - val_loss: -5.2575\n",
      "Epoch 1098/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2428 - val_loss: -4.8822\n",
      "Epoch 1099/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3085 - val_loss: -4.7253\n",
      "Epoch 1100/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3391 - val_loss: -5.3363\n",
      "Epoch 1101/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4102 - val_loss: 1.1261\n",
      "Epoch 1102/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2158 - val_loss: -5.2240\n",
      "Epoch 1103/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4488 - val_loss: -5.2900\n",
      "Epoch 1104/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3186 - val_loss: -5.2783\n",
      "Epoch 1105/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3655 - val_loss: -4.6779\n",
      "Epoch 1106/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4880 - val_loss: -5.2050\n",
      "Epoch 1107/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1551 - val_loss: -5.2148\n",
      "Epoch 1108/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2682 - val_loss: -5.1721\n",
      "Epoch 1109/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4632 - val_loss: -5.1602\n",
      "Epoch 1110/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4576 - val_loss: -5.2304\n",
      "Epoch 1111/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3776 - val_loss: -5.1777\n",
      "Epoch 1112/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4420 - val_loss: -5.0994\n",
      "Epoch 1113/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4033 - val_loss: -5.1052\n",
      "Epoch 1114/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3923 - val_loss: -5.3701\n",
      "Epoch 1115/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.3604 - val_loss: -5.2820\n",
      "Epoch 1116/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5124 - val_loss: -5.1990\n",
      "Epoch 1117/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2426 - val_loss: -4.0934\n",
      "Epoch 1118/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4348 - val_loss: -4.6492\n",
      "Epoch 1119/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2567 - val_loss: -5.1571\n",
      "Epoch 1120/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4268 - val_loss: -4.7187\n",
      "Epoch 1121/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4687 - val_loss: -5.2415\n",
      "Epoch 1122/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4025 - val_loss: -4.3271\n",
      "Epoch 1123/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4221 - val_loss: -5.0289\n",
      "Epoch 1124/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5127 - val_loss: -5.3126\n",
      "Epoch 1125/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3299 - val_loss: -5.2825\n",
      "Epoch 1126/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4633 - val_loss: -5.2378\n",
      "Epoch 1127/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4349 - val_loss: -5.1731\n",
      "Epoch 1128/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5038 - val_loss: -5.1390\n",
      "Epoch 1129/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3859 - val_loss: -5.2519\n",
      "Epoch 1130/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4733 - val_loss: -5.1620\n",
      "Epoch 1131/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5476 - val_loss: -5.3405\n",
      "Epoch 1132/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4996 - val_loss: -5.1772\n",
      "Epoch 1133/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4241 - val_loss: -4.8036\n",
      "Epoch 1134/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3876 - val_loss: -5.2382\n",
      "Epoch 1135/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5111 - val_loss: -5.0086\n",
      "Epoch 1136/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4889 - val_loss: -4.7241\n",
      "Epoch 1137/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3986 - val_loss: -5.3389\n",
      "Epoch 1138/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4936 - val_loss: -4.2876\n",
      "Epoch 1139/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3697 - val_loss: -4.4245\n",
      "Epoch 1140/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4213 - val_loss: -5.0531\n",
      "Epoch 1141/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4584 - val_loss: -5.3046\n",
      "Epoch 1142/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3649 - val_loss: -5.0579\n",
      "Epoch 1143/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5214 - val_loss: -5.1457\n",
      "Epoch 1144/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3037 - val_loss: -5.1641\n",
      "Epoch 1145/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4632 - val_loss: -3.8443\n",
      "Epoch 1146/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4602 - val_loss: -5.2985\n",
      "Epoch 1147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3714 - val_loss: -4.9129\n",
      "Epoch 1148/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5284 - val_loss: -4.6878\n",
      "Epoch 1149/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4630 - val_loss: -5.2219\n",
      "Epoch 1150/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5236 - val_loss: -5.3610\n",
      "Epoch 1151/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4498 - val_loss: -5.3213\n",
      "Epoch 1152/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4421 - val_loss: -5.2303\n",
      "Epoch 1153/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.2680 - val_loss: -5.1700\n",
      "Epoch 1154/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4758 - val_loss: -5.0542\n",
      "Epoch 1155/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4994 - val_loss: -5.1446\n",
      "Epoch 1156/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2245 - val_loss: -5.0671\n",
      "Epoch 1157/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3005 - val_loss: -4.7280\n",
      "Epoch 1158/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4094 - val_loss: -5.2426\n",
      "Epoch 1159/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4412 - val_loss: -5.0397\n",
      "Epoch 1160/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4973 - val_loss: -4.8725\n",
      "Epoch 1161/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3075 - val_loss: -5.0891\n",
      "Epoch 1162/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4167 - val_loss: -5.2721\n",
      "Epoch 1163/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4496 - val_loss: -5.1576\n",
      "Epoch 1164/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3999 - val_loss: -4.5253\n",
      "Epoch 1165/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5321 - val_loss: -5.1671\n",
      "Epoch 1166/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4420 - val_loss: -5.0478\n",
      "Epoch 1167/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.5405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.5405 - val_loss: -5.3851\n",
      "Epoch 1168/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3867 - val_loss: -5.2872\n",
      "Epoch 1169/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5619 - val_loss: -5.2882\n",
      "Epoch 1170/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3755 - val_loss: -4.7878\n",
      "Epoch 1171/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5158 - val_loss: -5.3048\n",
      "Epoch 1172/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4370 - val_loss: -4.7927\n",
      "Epoch 1173/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4575 - val_loss: -5.2375\n",
      "Epoch 1174/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4784 - val_loss: -5.2080\n",
      "Epoch 1175/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4908 - val_loss: -4.8989\n",
      "Epoch 1176/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3585 - val_loss: -4.8778\n",
      "Epoch 1177/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3173 - val_loss: -4.8260\n",
      "Epoch 1178/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2309 - val_loss: -5.3401\n",
      "Epoch 1179/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4812 - val_loss: -4.5112\n",
      "Epoch 1180/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3834 - val_loss: -5.3233\n",
      "Epoch 1181/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4618 - val_loss: -4.8797\n",
      "Epoch 1182/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4217 - val_loss: -5.0064\n",
      "Epoch 1183/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5281 - val_loss: -4.4466\n",
      "Epoch 1184/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3441 - val_loss: -5.1428\n",
      "Epoch 1185/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5085 - val_loss: -5.2496\n",
      "Epoch 1186/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3804 - val_loss: -5.3145\n",
      "Epoch 1187/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4423 - val_loss: -5.3188\n",
      "Epoch 1188/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4809 - val_loss: -4.8788\n",
      "Epoch 1189/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5707 - val_loss: -4.9364\n",
      "Epoch 1190/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3763 - val_loss: -5.1598\n",
      "Epoch 1191/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4430 - val_loss: -4.2142\n",
      "Epoch 1192/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2847 - val_loss: -4.6727\n",
      "Epoch 1193/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4809 - val_loss: -5.1358\n",
      "Epoch 1194/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4907 - val_loss: -5.1197\n",
      "Epoch 1195/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3570 - val_loss: -4.7250\n",
      "Epoch 1196/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4797 - val_loss: -5.3147\n",
      "Epoch 1197/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4488 - val_loss: -5.2635\n",
      "Epoch 1198/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4645 - val_loss: -5.0236\n",
      "Epoch 1199/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3837 - val_loss: -4.7907\n",
      "Epoch 1200/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4155 - val_loss: -5.3320\n",
      "Epoch 1201/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5624 - val_loss: -5.3530\n",
      "Epoch 1202/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4078 - val_loss: -4.5992\n",
      "Epoch 1203/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4273 - val_loss: -4.9594\n",
      "Epoch 1204/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4578 - val_loss: -5.0168\n",
      "Epoch 1205/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4895 - val_loss: -4.7761\n",
      "Epoch 1206/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4397 - val_loss: -5.1114\n",
      "Epoch 1207/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5608 - val_loss: -4.4299\n",
      "Epoch 1208/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1278 - val_loss: -5.2944\n",
      "Epoch 1209/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5357 - val_loss: -4.9709\n",
      "Epoch 1210/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4924 - val_loss: -5.2141\n",
      "Epoch 1211/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4271 - val_loss: -4.0816\n",
      "Epoch 1212/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4084 - val_loss: -5.1149\n",
      "Epoch 1213/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4440 - val_loss: -5.3454\n",
      "Epoch 1214/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4869 - val_loss: -3.6795\n",
      "Epoch 1215/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4818 - val_loss: -5.2843\n",
      "Epoch 1216/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3976 - val_loss: -4.8675\n",
      "Epoch 1217/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3593 - val_loss: -5.1630\n",
      "Epoch 1218/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5468 - val_loss: -4.6656\n",
      "Epoch 1219/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4437 - val_loss: -5.1159\n",
      "Epoch 1220/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4929 - val_loss: -5.1023\n",
      "Epoch 1221/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3073 - val_loss: -5.1823\n",
      "Epoch 1222/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5680 - val_loss: -5.1065\n",
      "Epoch 1223/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4903 - val_loss: -5.2380\n",
      "Epoch 1224/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4796 - val_loss: -5.1512\n",
      "Epoch 1225/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2990 - val_loss: -5.2270\n",
      "Epoch 1226/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4742 - val_loss: -5.1988\n",
      "Epoch 1227/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5021 - val_loss: -3.4328\n",
      "Epoch 1228/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4486 - val_loss: -5.1287\n",
      "Epoch 1229/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4868 - val_loss: -4.9726\n",
      "Epoch 1230/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5166 - val_loss: -5.1630\n",
      "Epoch 1231/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4925 - val_loss: -5.0395\n",
      "Epoch 1232/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4476 - val_loss: -5.1170\n",
      "Epoch 1233/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4332 - val_loss: -5.0604\n",
      "Epoch 1234/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4799 - val_loss: -5.0759\n",
      "Epoch 1235/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3728 - val_loss: -4.9736\n",
      "Epoch 1236/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4454 - val_loss: -5.2556\n",
      "Epoch 1237/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4271 - val_loss: -5.1251\n",
      "Epoch 1238/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: -5.4791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/SimulatedDataPretrainedModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 32s 225ms/step - loss: -5.4791 - val_loss: -5.4092\n",
      "Epoch 1239/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4026 - val_loss: -5.2472\n",
      "Epoch 1240/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5056 - val_loss: -2.1934\n",
      "Epoch 1241/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4233 - val_loss: -5.1100\n",
      "Epoch 1242/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3540 - val_loss: -4.8398\n",
      "Epoch 1243/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3023 - val_loss: -5.1765\n",
      "Epoch 1244/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4800 - val_loss: -4.0278\n",
      "Epoch 1245/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4695 - val_loss: -5.2110\n",
      "Epoch 1246/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5061 - val_loss: -5.1255\n",
      "Epoch 1247/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4201 - val_loss: -5.0600\n",
      "Epoch 1248/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5418 - val_loss: -4.7257\n",
      "Epoch 1249/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4102 - val_loss: -5.1790\n",
      "Epoch 1250/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4807 - val_loss: -5.2828\n",
      "Epoch 1251/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4974 - val_loss: -4.9035\n",
      "Epoch 1252/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5084 - val_loss: -5.3204\n",
      "Epoch 1253/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5230 - val_loss: -5.3865\n",
      "Epoch 1254/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4731 - val_loss: -5.2494\n",
      "Epoch 1255/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5429 - val_loss: -5.0476\n",
      "Epoch 1256/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4816 - val_loss: -5.0038\n",
      "Epoch 1257/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4328 - val_loss: -5.2973\n",
      "Epoch 1258/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2679 - val_loss: -4.0825\n",
      "Epoch 1259/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.9107 - val_loss: -4.7769\n",
      "Epoch 1260/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.3138 - val_loss: -4.6967\n",
      "Epoch 1261/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4512 - val_loss: -4.3240\n",
      "Epoch 1262/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4768 - val_loss: -5.3057\n",
      "Epoch 1263/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.2418 - val_loss: -5.0552\n",
      "Epoch 1264/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4717 - val_loss: -4.9961\n",
      "Epoch 1265/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4952 - val_loss: -5.1532\n",
      "Epoch 1266/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4286 - val_loss: -5.3153\n",
      "Epoch 1267/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5281 - val_loss: -5.3085\n",
      "Epoch 1268/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3745 - val_loss: -5.0203\n",
      "Epoch 1269/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4696 - val_loss: -5.2684\n",
      "Epoch 1270/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4873 - val_loss: -5.2176\n",
      "Epoch 1271/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4896 - val_loss: -5.1504\n",
      "Epoch 1272/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4182 - val_loss: -4.8796\n",
      "Epoch 1273/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5083 - val_loss: -5.0449\n",
      "Epoch 1274/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5736 - val_loss: -4.8352\n",
      "Epoch 1275/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5355 - val_loss: -5.0876\n",
      "Epoch 1276/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5298 - val_loss: -4.0977\n",
      "Epoch 1277/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4579 - val_loss: -5.1876\n",
      "Epoch 1278/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3542 - val_loss: -5.0015\n",
      "Epoch 1279/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5662 - val_loss: -5.1968\n",
      "Epoch 1280/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4723 - val_loss: -4.6746\n",
      "Epoch 1281/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4805 - val_loss: -5.2183\n",
      "Epoch 1282/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5048 - val_loss: -5.1402\n",
      "Epoch 1283/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5282 - val_loss: -4.6278\n",
      "Epoch 1284/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5248 - val_loss: -4.9542\n",
      "Epoch 1285/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4853 - val_loss: -5.2210\n",
      "Epoch 1286/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3785 - val_loss: -4.8072\n",
      "Epoch 1287/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5249 - val_loss: -4.5714\n",
      "Epoch 1288/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5753 - val_loss: -4.7689\n",
      "Epoch 1289/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4086 - val_loss: -5.3547\n",
      "Epoch 1290/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5157 - val_loss: -3.8815\n",
      "Epoch 1291/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3896 - val_loss: -5.2007\n",
      "Epoch 1292/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5214 - val_loss: -4.9765\n",
      "Epoch 1293/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5171 - val_loss: -4.4809\n",
      "Epoch 1294/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4446 - val_loss: -5.2177\n",
      "Epoch 1295/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4943 - val_loss: -5.1962\n",
      "Epoch 1296/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4682 - val_loss: -5.1099\n",
      "Epoch 1297/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5163 - val_loss: -5.1261\n",
      "Epoch 1298/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5652 - val_loss: -5.2579\n",
      "Epoch 1299/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5438 - val_loss: -5.0901\n",
      "Epoch 1300/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4938 - val_loss: -4.0951\n",
      "Epoch 1301/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3119 - val_loss: -5.0284\n",
      "Epoch 1302/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5256 - val_loss: -4.9998\n",
      "Epoch 1303/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5250 - val_loss: -4.6474\n",
      "Epoch 1304/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4850 - val_loss: -4.8618\n",
      "Epoch 1305/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3607 - val_loss: -5.2017\n",
      "Epoch 1306/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3987 - val_loss: -4.9484\n",
      "Epoch 1307/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5533 - val_loss: -4.1684\n",
      "Epoch 1308/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4459 - val_loss: -4.9426\n",
      "Epoch 1309/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4849 - val_loss: -5.1660\n",
      "Epoch 1310/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4502 - val_loss: -5.1302\n",
      "Epoch 1311/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5606 - val_loss: -4.8942\n",
      "Epoch 1312/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5106 - val_loss: -5.3233\n",
      "Epoch 1313/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4228 - val_loss: -5.0550\n",
      "Epoch 1314/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4292 - val_loss: -4.8877\n",
      "Epoch 1315/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4622 - val_loss: -5.1366\n",
      "Epoch 1316/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5244 - val_loss: -4.5150\n",
      "Epoch 1317/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5843 - val_loss: -4.5800\n",
      "Epoch 1318/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3959 - val_loss: -4.2165\n",
      "Epoch 1319/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5663 - val_loss: -4.5870\n",
      "Epoch 1320/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4361 - val_loss: -5.2016\n",
      "Epoch 1321/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4945 - val_loss: -5.0774\n",
      "Epoch 1322/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5284 - val_loss: -5.3232\n",
      "Epoch 1323/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4870 - val_loss: -5.1580\n",
      "Epoch 1324/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5582 - val_loss: -3.9149\n",
      "Epoch 1325/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4312 - val_loss: -5.1600\n",
      "Epoch 1326/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5772 - val_loss: -5.0280\n",
      "Epoch 1327/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5293 - val_loss: -5.2281\n",
      "Epoch 1328/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4953 - val_loss: -5.1522\n",
      "Epoch 1329/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5520 - val_loss: -5.1399\n",
      "Epoch 1330/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.2463 - val_loss: -5.3739\n",
      "Epoch 1331/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3580 - val_loss: -4.4178\n",
      "Epoch 1332/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5289 - val_loss: -5.0937\n",
      "Epoch 1333/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5075 - val_loss: -5.3385\n",
      "Epoch 1334/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0211 - val_loss: -5.1586\n",
      "Epoch 1335/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4302 - val_loss: -5.1203\n",
      "Epoch 1336/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3756 - val_loss: -5.2288\n",
      "Epoch 1337/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4057 - val_loss: -4.8486\n",
      "Epoch 1338/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5102 - val_loss: -4.7353\n",
      "Epoch 1339/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5269 - val_loss: -5.2553\n",
      "Epoch 1340/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5334 - val_loss: -4.7656\n",
      "Epoch 1341/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5267 - val_loss: -5.1380\n",
      "Epoch 1342/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4674 - val_loss: -5.2685\n",
      "Epoch 1343/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5568 - val_loss: -4.9799\n",
      "Epoch 1344/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4854 - val_loss: -4.5413\n",
      "Epoch 1345/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5377 - val_loss: -5.2547\n",
      "Epoch 1346/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4759 - val_loss: -5.1233\n",
      "Epoch 1347/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5108 - val_loss: -5.1200\n",
      "Epoch 1348/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4773 - val_loss: -5.3092\n",
      "Epoch 1349/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5839 - val_loss: -5.2995\n",
      "Epoch 1350/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5019 - val_loss: -4.4247\n",
      "Epoch 1351/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5721 - val_loss: -4.3601\n",
      "Epoch 1352/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -4.9705 - val_loss: -5.1435\n",
      "Epoch 1353/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2654 - val_loss: -4.9712\n",
      "Epoch 1354/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3604 - val_loss: -5.3222\n",
      "Epoch 1355/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5141 - val_loss: -5.3131\n",
      "Epoch 1356/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5065 - val_loss: -5.0583\n",
      "Epoch 1357/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4513 - val_loss: -5.2330\n",
      "Epoch 1358/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4528 - val_loss: -4.4566\n",
      "Epoch 1359/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4108 - val_loss: -4.8952\n",
      "Epoch 1360/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5760 - val_loss: -4.4890\n",
      "Epoch 1361/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3921 - val_loss: -5.2096\n",
      "Epoch 1362/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5820 - val_loss: -4.9071\n",
      "Epoch 1363/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4854 - val_loss: -3.4478\n",
      "Epoch 1364/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4384 - val_loss: -5.2889\n",
      "Epoch 1365/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4542 - val_loss: -5.0395\n",
      "Epoch 1366/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5458 - val_loss: -4.9616\n",
      "Epoch 1367/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5066 - val_loss: -4.1547\n",
      "Epoch 1368/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4589 - val_loss: -5.2694\n",
      "Epoch 1369/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3157 - val_loss: -5.3473\n",
      "Epoch 1370/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5392 - val_loss: -3.9319\n",
      "Epoch 1371/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4904 - val_loss: -4.8602\n",
      "Epoch 1372/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3215 - val_loss: -4.6605\n",
      "Epoch 1373/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3843 - val_loss: -4.5818\n",
      "Epoch 1374/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4188 - val_loss: -4.8544\n",
      "Epoch 1375/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5514 - val_loss: -5.3070\n",
      "Epoch 1376/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4554 - val_loss: -4.8700\n",
      "Epoch 1377/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5011 - val_loss: -4.9975\n",
      "Epoch 1378/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5856 - val_loss: -5.0495\n",
      "Epoch 1379/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5820 - val_loss: -5.0070\n",
      "Epoch 1380/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4760 - val_loss: -5.1110\n",
      "Epoch 1381/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4087 - val_loss: -5.1329\n",
      "Epoch 1382/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5410 - val_loss: -5.0677\n",
      "Epoch 1383/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6077 - val_loss: -5.0660\n",
      "Epoch 1384/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4717 - val_loss: -4.8344\n",
      "Epoch 1385/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4963 - val_loss: -5.3441\n",
      "Epoch 1386/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5841 - val_loss: -4.8412\n",
      "Epoch 1387/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3974 - val_loss: -5.0345\n",
      "Epoch 1388/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5504 - val_loss: -4.6002\n",
      "Epoch 1389/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5775 - val_loss: -5.2576\n",
      "Epoch 1390/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5066 - val_loss: -5.3763\n",
      "Epoch 1391/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4332 - val_loss: -5.3224\n",
      "Epoch 1392/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4353 - val_loss: -5.1988\n",
      "Epoch 1393/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5984 - val_loss: -5.3082\n",
      "Epoch 1394/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5357 - val_loss: -5.0464\n",
      "Epoch 1395/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5844 - val_loss: -4.7943\n",
      "Epoch 1396/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5178 - val_loss: -5.3048\n",
      "Epoch 1397/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4888 - val_loss: -5.3960\n",
      "Epoch 1398/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5451 - val_loss: -5.1409\n",
      "Epoch 1399/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5789 - val_loss: -5.1487\n",
      "Epoch 1400/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4749 - val_loss: -4.9402\n",
      "Epoch 1401/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6094 - val_loss: -3.2204\n",
      "Epoch 1402/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5047 - val_loss: -4.6341\n",
      "Epoch 1403/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5737 - val_loss: -4.9977\n",
      "Epoch 1404/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4997 - val_loss: -4.9571\n",
      "Epoch 1405/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.4319 - val_loss: -5.0086\n",
      "Epoch 1406/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4895 - val_loss: -5.2224\n",
      "Epoch 1407/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5403 - val_loss: -5.2398\n",
      "Epoch 1408/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5592 - val_loss: -5.3529\n",
      "Epoch 1409/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5127 - val_loss: -5.3781\n",
      "Epoch 1410/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3209 - val_loss: -5.2945\n",
      "Epoch 1411/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4822 - val_loss: -5.2985\n",
      "Epoch 1412/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5091 - val_loss: -4.4270\n",
      "Epoch 1413/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4657 - val_loss: -5.1403\n",
      "Epoch 1414/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5524 - val_loss: -5.2743\n",
      "Epoch 1415/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5007 - val_loss: -4.9169\n",
      "Epoch 1416/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5668 - val_loss: -5.2358\n",
      "Epoch 1417/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4866 - val_loss: -4.8830\n",
      "Epoch 1418/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4672 - val_loss: -5.0066\n",
      "Epoch 1419/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5577 - val_loss: -5.1347\n",
      "Epoch 1420/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5730 - val_loss: -5.3915\n",
      "Epoch 1421/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4212 - val_loss: -4.5070\n",
      "Epoch 1422/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5620 - val_loss: -5.1742\n",
      "Epoch 1423/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4977 - val_loss: -4.8602\n",
      "Epoch 1424/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5291 - val_loss: -5.0582\n",
      "Epoch 1425/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5029 - val_loss: -4.9939\n",
      "Epoch 1426/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4136 - val_loss: -5.2225\n",
      "Epoch 1427/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4496 - val_loss: -5.3045\n",
      "Epoch 1428/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4341 - val_loss: -5.2680\n",
      "Epoch 1429/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5356 - val_loss: -5.2438\n",
      "Epoch 1430/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5636 - val_loss: -5.2010\n",
      "Epoch 1431/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6213 - val_loss: -5.3358\n",
      "Epoch 1432/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5114 - val_loss: -5.2329\n",
      "Epoch 1433/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5175 - val_loss: -4.7275\n",
      "Epoch 1434/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5389 - val_loss: -5.1407\n",
      "Epoch 1435/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4392 - val_loss: -5.1313\n",
      "Epoch 1436/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5785 - val_loss: -5.0910\n",
      "Epoch 1437/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3964 - val_loss: -5.1549\n",
      "Epoch 1438/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5724 - val_loss: -5.0608\n",
      "Epoch 1439/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4886 - val_loss: -5.2306\n",
      "Epoch 1440/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4928 - val_loss: -5.1582\n",
      "Epoch 1441/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5522 - val_loss: -5.3306\n",
      "Epoch 1442/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5824 - val_loss: -5.3385\n",
      "Epoch 1443/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5886 - val_loss: -5.1629\n",
      "Epoch 1444/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1266 - val_loss: -4.2472\n",
      "Epoch 1445/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4405 - val_loss: -3.6087\n",
      "Epoch 1446/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4930 - val_loss: -5.0037\n",
      "Epoch 1447/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5017 - val_loss: -5.3111\n",
      "Epoch 1448/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4250 - val_loss: -4.7521\n",
      "Epoch 1449/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5110 - val_loss: -5.2438\n",
      "Epoch 1450/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5984 - val_loss: -4.7204\n",
      "Epoch 1451/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4359 - val_loss: -5.0543\n",
      "Epoch 1452/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5205 - val_loss: -5.1736\n",
      "Epoch 1453/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4705 - val_loss: -5.2395\n",
      "Epoch 1454/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4318 - val_loss: -5.2744\n",
      "Epoch 1455/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3924 - val_loss: -5.1741\n",
      "Epoch 1456/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5030 - val_loss: -5.2519\n",
      "Epoch 1457/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4960 - val_loss: -4.5471\n",
      "Epoch 1458/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5050 - val_loss: -5.0882\n",
      "Epoch 1459/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5430 - val_loss: -5.3061\n",
      "Epoch 1460/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5868 - val_loss: -4.8657\n",
      "Epoch 1461/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4921 - val_loss: -5.2227\n",
      "Epoch 1462/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5669 - val_loss: -5.3182\n",
      "Epoch 1463/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5644 - val_loss: -5.2577\n",
      "Epoch 1464/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5509 - val_loss: -5.2971\n",
      "Epoch 1465/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6398 - val_loss: -3.9552\n",
      "Epoch 1466/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4480 - val_loss: -5.3210\n",
      "Epoch 1467/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4996 - val_loss: -5.0661\n",
      "Epoch 1468/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5226 - val_loss: -4.6576\n",
      "Epoch 1469/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5599 - val_loss: -4.8212\n",
      "Epoch 1470/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5269 - val_loss: -5.2210\n",
      "Epoch 1471/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5445 - val_loss: -4.9351\n",
      "Epoch 1472/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4807 - val_loss: -5.2752\n",
      "Epoch 1473/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5964 - val_loss: -4.6512\n",
      "Epoch 1474/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5738 - val_loss: -5.1483\n",
      "Epoch 1475/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5013 - val_loss: -5.1446\n",
      "Epoch 1476/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4490 - val_loss: -5.1303\n",
      "Epoch 1477/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5331 - val_loss: -5.0759\n",
      "Epoch 1478/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5724 - val_loss: -5.1286\n",
      "Epoch 1479/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6155 - val_loss: -4.9564\n",
      "Epoch 1480/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4226 - val_loss: -5.0224\n",
      "Epoch 1481/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5687 - val_loss: -5.1044\n",
      "Epoch 1482/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3979 - val_loss: -4.8256\n",
      "Epoch 1483/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5012 - val_loss: -5.3089\n",
      "Epoch 1484/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4980 - val_loss: -5.1009\n",
      "Epoch 1485/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5667 - val_loss: -4.6426\n",
      "Epoch 1486/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5935 - val_loss: -0.9136\n",
      "Epoch 1487/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4252 - val_loss: -3.8248\n",
      "Epoch 1488/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5492 - val_loss: -4.8249\n",
      "Epoch 1489/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6243 - val_loss: -5.0180\n",
      "Epoch 1490/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5431 - val_loss: -5.2822\n",
      "Epoch 1491/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5745 - val_loss: -5.2729\n",
      "Epoch 1492/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.5351 - val_loss: -4.6115\n",
      "Epoch 1493/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5194 - val_loss: -4.9275\n",
      "Epoch 1494/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6159 - val_loss: -5.1354\n",
      "Epoch 1495/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5179 - val_loss: -4.7794\n",
      "Epoch 1496/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4948 - val_loss: -4.4272\n",
      "Epoch 1497/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1860 - val_loss: -4.8782\n",
      "Epoch 1498/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5540 - val_loss: -5.0208\n",
      "Epoch 1499/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4775 - val_loss: -4.9158\n",
      "Epoch 1500/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5315 - val_loss: -5.1769\n",
      "Epoch 1501/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5067 - val_loss: -4.9847\n",
      "Epoch 1502/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6097 - val_loss: -4.9351\n",
      "Epoch 1503/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4762 - val_loss: -5.2059\n",
      "Epoch 1504/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4137 - val_loss: -5.3386\n",
      "Epoch 1505/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5851 - val_loss: -5.2183\n",
      "Epoch 1506/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6020 - val_loss: -5.1663\n",
      "Epoch 1507/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6189 - val_loss: -4.4892\n",
      "Epoch 1508/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2572 - val_loss: -4.9468\n",
      "Epoch 1509/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5777 - val_loss: -4.9879\n",
      "Epoch 1510/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5880 - val_loss: -4.4507\n",
      "Epoch 1511/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -4.8808 - val_loss: -4.7870\n",
      "Epoch 1512/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.1314 - val_loss: -3.0336\n",
      "Epoch 1513/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.0522 - val_loss: -5.0554\n",
      "Epoch 1514/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.2715 - val_loss: -5.2209\n",
      "Epoch 1515/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4318 - val_loss: -5.2076\n",
      "Epoch 1516/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4167 - val_loss: -5.2794\n",
      "Epoch 1517/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4338 - val_loss: -4.7961\n",
      "Epoch 1518/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4951 - val_loss: -4.5231\n",
      "Epoch 1519/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3543 - val_loss: -4.4614\n",
      "Epoch 1520/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5223 - val_loss: -4.9850\n",
      "Epoch 1521/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4040 - val_loss: -5.1651\n",
      "Epoch 1522/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5193 - val_loss: -4.8856\n",
      "Epoch 1523/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5819 - val_loss: -5.2149\n",
      "Epoch 1524/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4848 - val_loss: -4.2980\n",
      "Epoch 1525/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4912 - val_loss: -5.0211\n",
      "Epoch 1526/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.5136 - val_loss: -4.8730\n",
      "Epoch 1527/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4855 - val_loss: -4.6065\n",
      "Epoch 1528/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5001 - val_loss: -5.2612\n",
      "Epoch 1529/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5389 - val_loss: -4.8610\n",
      "Epoch 1530/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4259 - val_loss: -4.5189\n",
      "Epoch 1531/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5879 - val_loss: -5.1655\n",
      "Epoch 1532/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5086 - val_loss: -5.2415\n",
      "Epoch 1533/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6124 - val_loss: -5.1445\n",
      "Epoch 1534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4722 - val_loss: -1.9260\n",
      "Epoch 1535/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4667 - val_loss: -4.2388\n",
      "Epoch 1536/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4939 - val_loss: -5.2036\n",
      "Epoch 1537/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5421 - val_loss: -5.2100\n",
      "Epoch 1538/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.3202 - val_loss: -4.4417\n",
      "Epoch 1539/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1442 - val_loss: -5.1973\n",
      "Epoch 1540/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4135 - val_loss: -4.9793\n",
      "Epoch 1541/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4539 - val_loss: -5.1979\n",
      "Epoch 1542/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4964 - val_loss: -5.3381\n",
      "Epoch 1543/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4888 - val_loss: -5.1121\n",
      "Epoch 1544/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4769 - val_loss: -4.8166\n",
      "Epoch 1545/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4723 - val_loss: -5.0227\n",
      "Epoch 1546/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5355 - val_loss: -4.7510\n",
      "Epoch 1547/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5881 - val_loss: -5.2815\n",
      "Epoch 1548/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5477 - val_loss: -5.2196\n",
      "Epoch 1549/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.3691 - val_loss: -4.8024\n",
      "Epoch 1550/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5210 - val_loss: -5.2416\n",
      "Epoch 1551/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5950 - val_loss: -5.2660\n",
      "Epoch 1552/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4717 - val_loss: -4.8205\n",
      "Epoch 1553/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6000 - val_loss: -5.1874\n",
      "Epoch 1554/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5946 - val_loss: -5.0645\n",
      "Epoch 1555/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4796 - val_loss: -4.8976\n",
      "Epoch 1556/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5416 - val_loss: -4.8522\n",
      "Epoch 1557/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4679 - val_loss: -5.2582\n",
      "Epoch 1558/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6003 - val_loss: -4.8621\n",
      "Epoch 1559/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5670 - val_loss: -5.3960\n",
      "Epoch 1560/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4522 - val_loss: -4.8239\n",
      "Epoch 1561/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6150 - val_loss: -4.3986\n",
      "Epoch 1562/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4476 - val_loss: -5.0252\n",
      "Epoch 1563/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6531 - val_loss: -4.9655\n",
      "Epoch 1564/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4254 - val_loss: -5.1434\n",
      "Epoch 1565/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.3739 - val_loss: -5.1913\n",
      "Epoch 1566/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6207 - val_loss: -3.2119\n",
      "Epoch 1567/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5139 - val_loss: -5.2435\n",
      "Epoch 1568/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5502 - val_loss: -5.1090\n",
      "Epoch 1569/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5993 - val_loss: -4.2609\n",
      "Epoch 1570/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4128 - val_loss: -5.1501\n",
      "Epoch 1571/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5646 - val_loss: -4.7799\n",
      "Epoch 1572/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5872 - val_loss: -5.0250\n",
      "Epoch 1573/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6211 - val_loss: -5.1744\n",
      "Epoch 1574/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5509 - val_loss: -5.0077\n",
      "Epoch 1575/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5316 - val_loss: -5.3345\n",
      "Epoch 1576/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6029 - val_loss: -5.1279\n",
      "Epoch 1577/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.1519 - val_loss: -5.2480\n",
      "Epoch 1578/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3472 - val_loss: -5.1117\n",
      "Epoch 1579/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4561 - val_loss: -4.3450\n",
      "Epoch 1580/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5054 - val_loss: -5.0557\n",
      "Epoch 1581/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5172 - val_loss: -4.7995\n",
      "Epoch 1582/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2749 - val_loss: -4.6205\n",
      "Epoch 1583/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3177 - val_loss: -4.8903\n",
      "Epoch 1584/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4305 - val_loss: -5.2998\n",
      "Epoch 1585/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5280 - val_loss: -5.3078\n",
      "Epoch 1586/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4069 - val_loss: -5.0240\n",
      "Epoch 1587/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5906 - val_loss: -4.6201\n",
      "Epoch 1588/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3701 - val_loss: -5.1018\n",
      "Epoch 1589/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5806 - val_loss: -4.9006\n",
      "Epoch 1590/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5860 - val_loss: -4.8802\n",
      "Epoch 1591/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6215 - val_loss: -4.6816\n",
      "Epoch 1592/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5046 - val_loss: -4.5426\n",
      "Epoch 1593/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4723 - val_loss: -5.2144\n",
      "Epoch 1594/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6186 - val_loss: -5.1333\n",
      "Epoch 1595/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.4999 - val_loss: -4.9633\n",
      "Epoch 1596/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5107 - val_loss: -5.2597\n",
      "Epoch 1597/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4014 - val_loss: -5.2034\n",
      "Epoch 1598/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5582 - val_loss: -4.3988\n",
      "Epoch 1599/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6305 - val_loss: -5.1232\n",
      "Epoch 1600/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5694 - val_loss: -5.3477\n",
      "Epoch 1601/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5612 - val_loss: -5.1046\n",
      "Epoch 1602/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5355 - val_loss: -5.2696\n",
      "Epoch 1603/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6080 - val_loss: -5.1679\n",
      "Epoch 1604/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4853 - val_loss: -5.0722\n",
      "Epoch 1605/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5541 - val_loss: -5.3128\n",
      "Epoch 1606/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.4105 - val_loss: -5.0716\n",
      "Epoch 1607/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6379 - val_loss: -4.6105\n",
      "Epoch 1608/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4362 - val_loss: -5.0749\n",
      "Epoch 1609/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6131 - val_loss: -5.3323\n",
      "Epoch 1610/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6045 - val_loss: -5.0387\n",
      "Epoch 1611/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5785 - val_loss: -3.9517\n",
      "Epoch 1612/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4678 - val_loss: -5.0730\n",
      "Epoch 1613/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5542 - val_loss: -5.2379\n",
      "Epoch 1614/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4343 - val_loss: -5.0828\n",
      "Epoch 1615/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6042 - val_loss: -5.2356\n",
      "Epoch 1616/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5444 - val_loss: -5.3083\n",
      "Epoch 1617/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5045 - val_loss: -4.8251\n",
      "Epoch 1618/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5921 - val_loss: -5.2162\n",
      "Epoch 1619/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5133 - val_loss: -5.2355\n",
      "Epoch 1620/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5906 - val_loss: -5.2965\n",
      "Epoch 1621/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6482 - val_loss: -4.9150\n",
      "Epoch 1622/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5999 - val_loss: -4.8989\n",
      "Epoch 1623/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4563 - val_loss: -5.0824\n",
      "Epoch 1624/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6224 - val_loss: -3.7660\n",
      "Epoch 1625/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4788 - val_loss: -4.5530\n",
      "Epoch 1626/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6252 - val_loss: -5.0744\n",
      "Epoch 1627/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4870 - val_loss: -4.8739\n",
      "Epoch 1628/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5025 - val_loss: -5.2316\n",
      "Epoch 1629/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4631 - val_loss: -4.8966\n",
      "Epoch 1630/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5558 - val_loss: -5.1749\n",
      "Epoch 1631/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6344 - val_loss: -5.0490\n",
      "Epoch 1632/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6363 - val_loss: -5.1142\n",
      "Epoch 1633/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4754 - val_loss: -5.2088\n",
      "Epoch 1634/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6281 - val_loss: -4.5502\n",
      "Epoch 1635/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6098 - val_loss: -5.2021\n",
      "Epoch 1636/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5931 - val_loss: -4.2495\n",
      "Epoch 1637/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4674 - val_loss: -4.5534\n",
      "Epoch 1638/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5442 - val_loss: -5.2455\n",
      "Epoch 1639/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5272 - val_loss: -5.0204\n",
      "Epoch 1640/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6479 - val_loss: -4.9796\n",
      "Epoch 1641/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6544 - val_loss: -5.2631\n",
      "Epoch 1642/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5486 - val_loss: -4.0794\n",
      "Epoch 1643/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5982 - val_loss: -5.0821\n",
      "Epoch 1644/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5719 - val_loss: -4.8609\n",
      "Epoch 1645/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5128 - val_loss: -5.0285\n",
      "Epoch 1646/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4066 - val_loss: -5.0515\n",
      "Epoch 1647/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4062 - val_loss: -5.1302\n",
      "Epoch 1648/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5777 - val_loss: -5.2338\n",
      "Epoch 1649/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5030 - val_loss: -5.1965\n",
      "Epoch 1650/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5927 - val_loss: -5.1107\n",
      "Epoch 1651/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5434 - val_loss: -4.8541\n",
      "Epoch 1652/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5202 - val_loss: -3.4284\n",
      "Epoch 1653/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5623 - val_loss: -4.5160\n",
      "Epoch 1654/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4948 - val_loss: -5.1780\n",
      "Epoch 1655/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6366 - val_loss: -5.0311\n",
      "Epoch 1656/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4701 - val_loss: -5.0224\n",
      "Epoch 1657/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6307 - val_loss: -4.9748\n",
      "Epoch 1658/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4850 - val_loss: -5.1020\n",
      "Epoch 1659/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5259 - val_loss: -5.2289\n",
      "Epoch 1660/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5908 - val_loss: -5.2758\n",
      "Epoch 1661/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5730 - val_loss: -5.1317\n",
      "Epoch 1662/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5809 - val_loss: -3.5800\n",
      "Epoch 1663/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5618 - val_loss: -5.2058\n",
      "Epoch 1664/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5736 - val_loss: -4.5793\n",
      "Epoch 1665/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5894 - val_loss: -4.3730\n",
      "Epoch 1666/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5979 - val_loss: -5.3488\n",
      "Epoch 1667/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5289 - val_loss: -2.5857\n",
      "Epoch 1668/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5080 - val_loss: -5.0401\n",
      "Epoch 1669/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6030 - val_loss: -5.1636\n",
      "Epoch 1670/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5640 - val_loss: -4.5266\n",
      "Epoch 1671/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6162 - val_loss: -5.2534\n",
      "Epoch 1672/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6343 - val_loss: -5.0712\n",
      "Epoch 1673/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6273 - val_loss: -5.0711\n",
      "Epoch 1674/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5855 - val_loss: -5.1596\n",
      "Epoch 1675/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5993 - val_loss: -4.9408\n",
      "Epoch 1676/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5182 - val_loss: -5.0188\n",
      "Epoch 1677/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4528 - val_loss: -5.0040\n",
      "Epoch 1678/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4957 - val_loss: -5.2266\n",
      "Epoch 1679/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5292 - val_loss: -5.3899\n",
      "Epoch 1680/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5875 - val_loss: -5.2035\n",
      "Epoch 1681/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6613 - val_loss: -5.1201\n",
      "Epoch 1682/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5554 - val_loss: -5.2501\n",
      "Epoch 1683/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6313 - val_loss: -5.2423\n",
      "Epoch 1684/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5568 - val_loss: -5.0000\n",
      "Epoch 1685/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5978 - val_loss: -4.2048\n",
      "Epoch 1686/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5215 - val_loss: -5.2097\n",
      "Epoch 1687/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.4134 - val_loss: -5.2152\n",
      "Epoch 1688/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6571 - val_loss: -4.6552\n",
      "Epoch 1689/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5224 - val_loss: -4.9168\n",
      "Epoch 1690/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6033 - val_loss: -4.7833\n",
      "Epoch 1691/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6298 - val_loss: -4.4283\n",
      "Epoch 1692/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2085 - val_loss: -4.9178\n",
      "Epoch 1693/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4634 - val_loss: -5.1243\n",
      "Epoch 1694/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4999 - val_loss: -4.8931\n",
      "Epoch 1695/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6072 - val_loss: -4.9709\n",
      "Epoch 1696/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5606 - val_loss: -5.0208\n",
      "Epoch 1697/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5510 - val_loss: -4.9977\n",
      "Epoch 1698/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5487 - val_loss: -5.2207\n",
      "Epoch 1699/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6243 - val_loss: -4.8168\n",
      "Epoch 1700/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3607 - val_loss: -5.1565\n",
      "Epoch 1701/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5170 - val_loss: -5.0350\n",
      "Epoch 1702/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6294 - val_loss: -5.0728\n",
      "Epoch 1703/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5619 - val_loss: -5.1039\n",
      "Epoch 1704/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5806 - val_loss: -2.8921\n",
      "Epoch 1705/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5102 - val_loss: -4.8893\n",
      "Epoch 1706/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5901 - val_loss: -4.9367\n",
      "Epoch 1707/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6059 - val_loss: -5.0132\n",
      "Epoch 1708/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6205 - val_loss: -4.7154\n",
      "Epoch 1709/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6489 - val_loss: -3.9756\n",
      "Epoch 1710/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4965 - val_loss: -5.0755\n",
      "Epoch 1711/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5944 - val_loss: -4.0134\n",
      "Epoch 1712/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6506 - val_loss: -5.0560\n",
      "Epoch 1713/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5506 - val_loss: -3.6952\n",
      "Epoch 1714/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5689 - val_loss: -5.1023\n",
      "Epoch 1715/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4643 - val_loss: -4.4057\n",
      "Epoch 1716/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6840 - val_loss: -4.9951\n",
      "Epoch 1717/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5291 - val_loss: -5.0771\n",
      "Epoch 1718/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6229 - val_loss: -5.3572\n",
      "Epoch 1719/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5913 - val_loss: -5.1521\n",
      "Epoch 1720/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4817 - val_loss: -5.1663\n",
      "Epoch 1721/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3391 - val_loss: -5.3251\n",
      "Epoch 1722/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5365 - val_loss: -4.8091\n",
      "Epoch 1723/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5185 - val_loss: -5.3421\n",
      "Epoch 1724/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5701 - val_loss: -5.0532\n",
      "Epoch 1725/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4445 - val_loss: -4.0623\n",
      "Epoch 1726/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5780 - val_loss: -5.1749\n",
      "Epoch 1727/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6241 - val_loss: -4.9136\n",
      "Epoch 1728/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4912 - val_loss: -4.8629\n",
      "Epoch 1729/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5389 - val_loss: -4.6065\n",
      "Epoch 1730/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4352 - val_loss: -5.3232\n",
      "Epoch 1731/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3637 - val_loss: -4.9287\n",
      "Epoch 1732/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5493 - val_loss: -5.3389\n",
      "Epoch 1733/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5569 - val_loss: -4.2086\n",
      "Epoch 1734/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4946 - val_loss: -5.2505\n",
      "Epoch 1735/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6411 - val_loss: -5.0618\n",
      "Epoch 1736/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5338 - val_loss: -3.7129\n",
      "Epoch 1737/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5831 - val_loss: -5.0648\n",
      "Epoch 1738/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3495 - val_loss: -5.1188\n",
      "Epoch 1739/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5528 - val_loss: -5.2102\n",
      "Epoch 1740/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5810 - val_loss: -4.7536\n",
      "Epoch 1741/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5448 - val_loss: -5.2505\n",
      "Epoch 1742/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5991 - val_loss: -5.0671\n",
      "Epoch 1743/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5820 - val_loss: -5.2295\n",
      "Epoch 1744/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5716 - val_loss: -5.0498\n",
      "Epoch 1745/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6195 - val_loss: -4.9676\n",
      "Epoch 1746/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5722 - val_loss: -3.9334\n",
      "Epoch 1747/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5061 - val_loss: -5.2303\n",
      "Epoch 1748/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6825 - val_loss: -4.4203\n",
      "Epoch 1749/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5700 - val_loss: -4.6029\n",
      "Epoch 1750/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6262 - val_loss: -4.5844\n",
      "Epoch 1751/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5754 - val_loss: -5.3577\n",
      "Epoch 1752/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6225 - val_loss: -5.2383\n",
      "Epoch 1753/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5492 - val_loss: -5.0946\n",
      "Epoch 1754/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5943 - val_loss: -4.8497\n",
      "Epoch 1755/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5828 - val_loss: -4.7370\n",
      "Epoch 1756/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5324 - val_loss: -5.1223\n",
      "Epoch 1757/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6391 - val_loss: -4.7812\n",
      "Epoch 1758/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5340 - val_loss: -4.8233\n",
      "Epoch 1759/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5967 - val_loss: -4.8876\n",
      "Epoch 1760/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5531 - val_loss: -5.1821\n",
      "Epoch 1761/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6709 - val_loss: -4.8752\n",
      "Epoch 1762/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5449 - val_loss: -4.4344\n",
      "Epoch 1763/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5573 - val_loss: -5.2137\n",
      "Epoch 1764/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5101 - val_loss: -5.1171\n",
      "Epoch 1765/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5919 - val_loss: -5.1259\n",
      "Epoch 1766/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6521 - val_loss: -5.0124\n",
      "Epoch 1767/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5326 - val_loss: -4.8200\n",
      "Epoch 1768/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6165 - val_loss: -4.1295\n",
      "Epoch 1769/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5377 - val_loss: -5.2726\n",
      "Epoch 1770/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6456 - val_loss: -4.1910\n",
      "Epoch 1771/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5857 - val_loss: -5.1920\n",
      "Epoch 1772/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.7042 - val_loss: -5.1586\n",
      "Epoch 1773/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6529 - val_loss: -5.1753\n",
      "Epoch 1774/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5502 - val_loss: -5.3081\n",
      "Epoch 1775/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6713 - val_loss: -4.3296\n",
      "Epoch 1776/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5478 - val_loss: -5.0633\n",
      "Epoch 1777/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5982 - val_loss: -4.5751\n",
      "Epoch 1778/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5001 - val_loss: -5.1779\n",
      "Epoch 1779/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5911 - val_loss: -3.8691\n",
      "Epoch 1780/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6301 - val_loss: -4.9495\n",
      "Epoch 1781/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5793 - val_loss: -4.9954\n",
      "Epoch 1782/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5378 - val_loss: -5.1005\n",
      "Epoch 1783/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5657 - val_loss: -4.7655\n",
      "Epoch 1784/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6932 - val_loss: -4.8766\n",
      "Epoch 1785/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5795 - val_loss: -4.2382\n",
      "Epoch 1786/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4222 - val_loss: -5.0764\n",
      "Epoch 1787/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5980 - val_loss: -5.1751\n",
      "Epoch 1788/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6110 - val_loss: -4.9453\n",
      "Epoch 1789/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6569 - val_loss: -4.8811\n",
      "Epoch 1790/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6152 - val_loss: -4.3361\n",
      "Epoch 1791/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6620 - val_loss: -5.2083\n",
      "Epoch 1792/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5055 - val_loss: -4.7009\n",
      "Epoch 1793/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6596 - val_loss: -4.7131\n",
      "Epoch 1794/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5807 - val_loss: -4.9124\n",
      "Epoch 1795/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6124 - val_loss: -4.2208\n",
      "Epoch 1796/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5503 - val_loss: -5.2208\n",
      "Epoch 1797/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6586 - val_loss: -5.3232\n",
      "Epoch 1798/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5443 - val_loss: -5.2860\n",
      "Epoch 1799/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6457 - val_loss: -4.9709\n",
      "Epoch 1800/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4513 - val_loss: -5.1751\n",
      "Epoch 1801/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6141 - val_loss: -4.9257\n",
      "Epoch 1802/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.7078 - val_loss: -4.9199\n",
      "Epoch 1803/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5882 - val_loss: -5.2582\n",
      "Epoch 1804/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6007 - val_loss: -5.2182\n",
      "Epoch 1805/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6317 - val_loss: -5.2851\n",
      "Epoch 1806/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5266 - val_loss: -4.9232\n",
      "Epoch 1807/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6892 - val_loss: -5.1383\n",
      "Epoch 1808/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5186 - val_loss: -4.6916\n",
      "Epoch 1809/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6680 - val_loss: -4.9314\n",
      "Epoch 1810/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6280 - val_loss: -4.9936\n",
      "Epoch 1811/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6263 - val_loss: -4.8602\n",
      "Epoch 1812/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6329 - val_loss: -5.1516\n",
      "Epoch 1813/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.6297 - val_loss: -5.0059\n",
      "Epoch 1814/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4424 - val_loss: -5.2649\n",
      "Epoch 1815/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6125 - val_loss: -4.9865\n",
      "Epoch 1816/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.6592 - val_loss: -5.0129\n",
      "Epoch 1817/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3829 - val_loss: -5.1336\n",
      "Epoch 1818/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.7194 - val_loss: -5.1278\n",
      "Epoch 1819/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5291 - val_loss: -5.1075\n",
      "Epoch 1820/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6987 - val_loss: -4.4514\n",
      "Epoch 1821/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6814 - val_loss: -4.7649\n",
      "Epoch 1822/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.1139 - val_loss: -4.7867\n",
      "Epoch 1823/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3189 - val_loss: -5.0762\n",
      "Epoch 1824/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5033 - val_loss: -4.5246\n",
      "Epoch 1825/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5177 - val_loss: -5.0409\n",
      "Epoch 1826/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6056 - val_loss: -5.1454\n",
      "Epoch 1827/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4848 - val_loss: -3.6723\n",
      "Epoch 1828/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5627 - val_loss: -5.3210\n",
      "Epoch 1829/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6455 - val_loss: -5.1290\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6877 - val_loss: -4.8353\n",
      "Epoch 1831/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.6830 - val_loss: -4.9346\n",
      "Epoch 1832/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5725 - val_loss: -4.4759\n",
      "Epoch 1833/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6573 - val_loss: -4.6245\n",
      "Epoch 1834/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6374 - val_loss: -4.9856\n",
      "Epoch 1835/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.3647 - val_loss: -4.8423\n",
      "Epoch 1836/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6172 - val_loss: -5.1316\n",
      "Epoch 1837/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6611 - val_loss: -5.0663\n",
      "Epoch 1838/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5243 - val_loss: -4.4627\n",
      "Epoch 1839/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6579 - val_loss: -4.9006\n",
      "Epoch 1840/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5877 - val_loss: -5.0975\n",
      "Epoch 1841/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6302 - val_loss: -5.0194\n",
      "Epoch 1842/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6847 - val_loss: -4.9687\n",
      "Epoch 1843/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6236 - val_loss: -4.8578\n",
      "Epoch 1844/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.8327 - val_loss: -5.1489\n",
      "Epoch 1845/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4950 - val_loss: -5.3687\n",
      "Epoch 1846/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4459 - val_loss: -5.4089\n",
      "Epoch 1847/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5540 - val_loss: -5.0204\n",
      "Epoch 1848/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5372 - val_loss: -5.0418\n",
      "Epoch 1849/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6265 - val_loss: -5.0728\n",
      "Epoch 1850/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4258 - val_loss: -5.1792\n",
      "Epoch 1851/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4792 - val_loss: -5.2270\n",
      "Epoch 1852/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5100 - val_loss: -4.9368\n",
      "Epoch 1853/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5189 - val_loss: -5.0219\n",
      "Epoch 1854/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5832 - val_loss: -4.1445\n",
      "Epoch 1855/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6047 - val_loss: -3.6399\n",
      "Epoch 1856/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4072 - val_loss: -5.1749\n",
      "Epoch 1857/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5357 - val_loss: -4.9009\n",
      "Epoch 1858/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6040 - val_loss: -4.9950\n",
      "Epoch 1859/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6171 - val_loss: -5.0096\n",
      "Epoch 1860/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5916 - val_loss: -4.8847\n",
      "Epoch 1861/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6544 - val_loss: -4.9800\n",
      "Epoch 1862/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6088 - val_loss: -4.8657\n",
      "Epoch 1863/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.4628 - val_loss: -5.1060\n",
      "Epoch 1864/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -4.9769 - val_loss: -4.8841\n",
      "Epoch 1865/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3778 - val_loss: -4.8833\n",
      "Epoch 1866/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4582 - val_loss: -4.5776\n",
      "Epoch 1867/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3100 - val_loss: -5.2544\n",
      "Epoch 1868/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4385 - val_loss: -3.5792\n",
      "Epoch 1869/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4258 - val_loss: -5.1003\n",
      "Epoch 1870/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5822 - val_loss: -5.2066\n",
      "Epoch 1871/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5775 - val_loss: -5.1437\n",
      "Epoch 1872/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5800 - val_loss: -4.5360\n",
      "Epoch 1873/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.5938 - val_loss: -5.1316\n",
      "Epoch 1874/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5120 - val_loss: -5.2459\n",
      "Epoch 1875/2000\n",
      "141/141 [==============================] - 24s 172ms/step - loss: -5.5882 - val_loss: -5.0701\n",
      "Epoch 1876/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5515 - val_loss: -5.2120\n",
      "Epoch 1877/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6658 - val_loss: -4.6442\n",
      "Epoch 1878/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5120 - val_loss: -5.0775\n",
      "Epoch 1879/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5269 - val_loss: -4.5956\n",
      "Epoch 1880/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6029 - val_loss: -0.7305\n",
      "Epoch 1881/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.4931 - val_loss: -4.6873\n",
      "Epoch 1882/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6672 - val_loss: -4.1062\n",
      "Epoch 1883/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6289 - val_loss: -5.0670\n",
      "Epoch 1884/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4800 - val_loss: -4.9711\n",
      "Epoch 1885/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6248 - val_loss: -5.1908\n",
      "Epoch 1886/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5866 - val_loss: -4.7570\n",
      "Epoch 1887/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6413 - val_loss: -5.1138\n",
      "Epoch 1888/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6463 - val_loss: -5.0519\n",
      "Epoch 1889/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6859 - val_loss: -5.0209\n",
      "Epoch 1890/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6621 - val_loss: -4.0400\n",
      "Epoch 1891/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6094 - val_loss: -4.9955\n",
      "Epoch 1892/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5665 - val_loss: -4.1589\n",
      "Epoch 1893/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.5380 - val_loss: -4.9633\n",
      "Epoch 1894/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.7106 - val_loss: -3.9072\n",
      "Epoch 1895/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6689 - val_loss: -4.7156\n",
      "Epoch 1896/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6728 - val_loss: -5.0981\n",
      "Epoch 1897/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6755 - val_loss: -5.1406\n",
      "Epoch 1898/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6801 - val_loss: -4.1429\n",
      "Epoch 1899/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6633 - val_loss: -4.5812\n",
      "Epoch 1900/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6744 - val_loss: -5.0526\n",
      "Epoch 1901/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.4280 - val_loss: -4.9672\n",
      "Epoch 1902/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6830 - val_loss: -5.1897\n",
      "Epoch 1903/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6080 - val_loss: -5.0852\n",
      "Epoch 1904/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5503 - val_loss: -4.8081\n",
      "Epoch 1905/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6471 - val_loss: -5.0861\n",
      "Epoch 1906/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6667 - val_loss: -5.0357\n",
      "Epoch 1907/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6069 - val_loss: -4.1059\n",
      "Epoch 1908/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5299 - val_loss: -5.2094\n",
      "Epoch 1909/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6805 - val_loss: -4.3573\n",
      "Epoch 1910/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5647 - val_loss: -5.2788\n",
      "Epoch 1911/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6713 - val_loss: -5.2026\n",
      "Epoch 1912/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6694 - val_loss: -4.2339\n",
      "Epoch 1913/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6537 - val_loss: -4.7446\n",
      "Epoch 1914/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6825 - val_loss: -0.3001\n",
      "Epoch 1915/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5910 - val_loss: -3.2308\n",
      "Epoch 1916/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6216 - val_loss: -5.1912\n",
      "Epoch 1917/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6332 - val_loss: -4.9392\n",
      "Epoch 1918/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.7214 - val_loss: -4.6259\n",
      "Epoch 1919/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6177 - val_loss: -5.0934\n",
      "Epoch 1920/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6919 - val_loss: -5.0707\n",
      "Epoch 1921/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6786 - val_loss: -4.3600\n",
      "Epoch 1922/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.2373 - val_loss: -5.1224\n",
      "Epoch 1923/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5477 - val_loss: -4.2704\n",
      "Epoch 1924/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4639 - val_loss: -4.5132\n",
      "Epoch 1925/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5676 - val_loss: -5.1060\n",
      "Epoch 1926/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5838 - val_loss: -5.0003\n",
      "Epoch 1927/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.6347 - val_loss: -4.3560\n",
      "Epoch 1928/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6397 - val_loss: -4.8331\n",
      "Epoch 1929/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -4.9889 - val_loss: -4.3661\n",
      "Epoch 1930/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.2507 - val_loss: -5.1513\n",
      "Epoch 1931/2000\n",
      "141/141 [==============================] - 24s 174ms/step - loss: -5.4279 - val_loss: -5.1535\n",
      "Epoch 1932/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3854 - val_loss: -4.7954\n",
      "Epoch 1933/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5090 - val_loss: -5.3622\n",
      "Epoch 1934/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5647 - val_loss: -4.2217\n",
      "Epoch 1935/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6022 - val_loss: -5.2219\n",
      "Epoch 1936/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5616 - val_loss: -4.9526\n",
      "Epoch 1937/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5712 - val_loss: -5.2243\n",
      "Epoch 1938/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.3965 - val_loss: -5.1822\n",
      "Epoch 1939/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6023 - val_loss: -5.1492\n",
      "Epoch 1940/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4406 - val_loss: -4.5779\n",
      "Epoch 1941/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5888 - val_loss: -5.2496\n",
      "Epoch 1942/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5043 - val_loss: -4.2792\n",
      "Epoch 1943/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6210 - val_loss: -4.8867\n",
      "Epoch 1944/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6447 - val_loss: -2.7254\n",
      "Epoch 1945/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6066 - val_loss: -4.4525\n",
      "Epoch 1946/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6287 - val_loss: -5.0462\n",
      "Epoch 1947/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3633 - val_loss: -3.8378\n",
      "Epoch 1948/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6831 - val_loss: -5.0804\n",
      "Epoch 1949/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4695 - val_loss: -5.2227\n",
      "Epoch 1950/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6769 - val_loss: -5.0582\n",
      "Epoch 1951/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6425 - val_loss: -5.0767\n",
      "Epoch 1952/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6745 - val_loss: -4.9096\n",
      "Epoch 1953/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5357 - val_loss: -4.8773\n",
      "Epoch 1954/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6110 - val_loss: -4.5220\n",
      "Epoch 1955/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.7156 - val_loss: -4.1644\n",
      "Epoch 1956/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6450 - val_loss: -5.0083\n",
      "Epoch 1957/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5523 - val_loss: -4.4428\n",
      "Epoch 1958/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6521 - val_loss: -5.1269\n",
      "Epoch 1959/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6540 - val_loss: -5.2477\n",
      "Epoch 1960/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6132 - val_loss: -3.5416\n",
      "Epoch 1961/2000\n",
      "141/141 [==============================] - 25s 177ms/step - loss: -5.6270 - val_loss: -5.2559\n",
      "Epoch 1962/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6664 - val_loss: -4.6664\n",
      "Epoch 1963/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6033 - val_loss: -5.1950\n",
      "Epoch 1964/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6316 - val_loss: -4.5662\n",
      "Epoch 1965/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4238 - val_loss: -4.1010\n",
      "Epoch 1966/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6580 - val_loss: -5.2078\n",
      "Epoch 1967/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5691 - val_loss: -4.9424\n",
      "Epoch 1968/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6718 - val_loss: -5.1532\n",
      "Epoch 1969/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6702 - val_loss: -5.0297\n",
      "Epoch 1970/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6436 - val_loss: -5.1615\n",
      "Epoch 1971/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6917 - val_loss: -4.9243\n",
      "Epoch 1972/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5385 - val_loss: -4.9041\n",
      "Epoch 1973/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6668 - val_loss: -4.9894\n",
      "Epoch 1974/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6478 - val_loss: -5.1666\n",
      "Epoch 1975/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6985 - val_loss: -5.0863\n",
      "Epoch 1976/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5812 - val_loss: -5.1777\n",
      "Epoch 1977/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.7023 - val_loss: -5.1743\n",
      "Epoch 1978/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6096 - val_loss: -5.2023\n",
      "Epoch 1979/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.6842 - val_loss: -4.8978\n",
      "Epoch 1980/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5057 - val_loss: -4.6025\n",
      "Epoch 1981/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -4.4686 - val_loss: -5.0711\n",
      "Epoch 1982/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.2661 - val_loss: -5.2704\n",
      "Epoch 1983/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4215 - val_loss: -5.1085\n",
      "Epoch 1984/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.3812 - val_loss: -5.1451\n",
      "Epoch 1985/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4647 - val_loss: -5.1442\n",
      "Epoch 1986/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4234 - val_loss: -4.6353\n",
      "Epoch 1987/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5493 - val_loss: -5.1033\n",
      "Epoch 1988/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.5233 - val_loss: -5.0600\n",
      "Epoch 1989/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4520 - val_loss: -3.4435\n",
      "Epoch 1990/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.5624 - val_loss: -5.0302\n",
      "Epoch 1991/2000\n",
      "141/141 [==============================] - 25s 178ms/step - loss: -5.5375 - val_loss: -5.1503\n",
      "Epoch 1992/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.3662 - val_loss: -5.3288\n",
      "Epoch 1993/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.4937 - val_loss: -4.8391\n",
      "Epoch 1994/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.5699 - val_loss: -4.9606\n",
      "Epoch 1995/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.5087 - val_loss: -5.0605\n",
      "Epoch 1996/2000\n",
      "141/141 [==============================] - 25s 173ms/step - loss: -5.5732 - val_loss: -4.7313\n",
      "Epoch 1997/2000\n",
      "141/141 [==============================] - 25s 175ms/step - loss: -5.6652 - val_loss: -5.0466\n",
      "Epoch 1998/2000\n",
      "141/141 [==============================] - 25s 176ms/step - loss: -5.6166 - val_loss: -5.1383\n",
      "Epoch 1999/2000\n",
      "141/141 [==============================] - 24s 173ms/step - loss: -5.6156 - val_loss: -3.9856\n",
      "Epoch 2000/2000\n",
      "141/141 [==============================] - 25s 174ms/step - loss: -5.4768 - val_loss: -3.2769\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/GklEQVR4nO2dd5gURdrAf7UBlhwXQUBZEEQks4KKEk7MAbMifgdyJkwnd6eeGRXOeJ5ypkNFFFHMiBlBoojkHCStklkW2F1YZndnpr4/umd3dnbiTuhe5v09zzw9XV1d/XZ3db1Vb1W9pbTWCIIgCMlHitUCCIIgCNYgCkAQBCFJEQUgCIKQpIgCEARBSFJEAQiCICQpaVYLEAlNmzbVbdq0sVoMQRCEasXSpUv3a60zfcOrlQJo06YNS5YssVoMQRCEaoVS6nd/4WICEgRBSFJEAQiCICQpogAEQRCSlGrVByAIQmIoLS1lx44dOBwOq0URIiAjI4NWrVqRnp4eVnxRAIIgVGLHjh3Uq1ePNm3aoJSyWhwhDLTW5OXlsWPHDrKyssI6R0xAgiBUwuFw0KRJEyn8qxFKKZo0aRJRq00UgCAIfpHCv/oR6TsTBWA1zhJYPhnELbcgCAlGFIDVzHkWvrwD1k21WhJBsA15eXl0796d7t2707x5c1q2bFm2X1JSEvTcJUuWcM8994S8xplnnhkTWWfPns0ll1wSk7QSjXQCW82RfcbWkW+tHIJgI5o0acKKFSsAGD16NHXr1uUf//hH2XGn00lamv/iKzs7m+zs7JDXWLBgQUxkrc5IC0AQhGrB8OHDuf322+nTpw/3338/ixYt4owzzqBHjx6ceeaZbNy4EahYIx89ejQjRoxgwIABtG3blnHjxpWlV7du3bL4AwYM4Oqrr6Zjx44MHToUz0qJ3377LR07dqRXr17cc889EdX0P/zwQ7p06ULnzp154IEHAHC5XAwfPpzOnTvTpUsX/vOf/wAwbtw4OnXqRNeuXbn++uujf1hhIi0AQRCC8sRXa1m3qyCmaXY6vj6PX3pqxOft2LGDBQsWkJqaSkFBAfPmzSMtLY0ZM2bw0EMP8dlnn1U6Z8OGDcyaNYvCwkJOPvlkRo4cWWmc/PLly1m7di3HH388ffv25eeffyY7O5vbbruNuXPnkpWVxZAhQ8KWc9euXTzwwAMsXbqURo0acd555zF16lRat27Nzp07WbNmDQCHDh0C4JlnnmHbtm3UrFmzLCwRSAtAEIRqwzXXXENqaioA+fn5XHPNNXTu3JlRo0axdu1av+dcfPHF1KxZk6ZNm9KsWTP27t1bKU7v3r1p1aoVKSkpdO/enZycHDZs2EDbtm3LxtRHogAWL17MgAEDyMzMJC0tjaFDhzJ37lzatm3L1q1bufvuu/n++++pX78+AF27dmXo0KG8//77AU1b8UBaAIIgBKUqNfV4UadOnbL/jz76KAMHDuSLL74gJyeHAQMG+D2nZs2aZf9TU1NxOp1VihMLGjVqxMqVK/nhhx944403+Pjjj5kwYQLffPMNc+fO5auvvmLs2LGsXr06IYpAWgCCIFRL8vPzadmyJQATJ06Mefonn3wyW7duJScnB4CPPvoo7HN79+7NnDlz2L9/Py6Xiw8//JD+/fuzf/9+3G43V111FWPGjGHZsmW43W62b9/OwIEDefbZZ8nPz+fw4cMxvx9/SAtAEIRqyf3338+wYcMYM2YMF198cczTr1WrFq+99hoXXHABderU4bTTTgsYd+bMmbRq1aps/5NPPuGZZ55h4MCBaK25+OKLGTx4MCtXruSmm27C7XYD8PTTT+NyubjxxhvJz89Ha80999xDw4YNY34//lC6Gk1Ays7O1sfcgjBf3gXLJ8GlL0Ov4VZLIwgArF+/nlNOOcVqMSzn8OHD1K1bF601d955J+3bt2fUqFFWixUUf+9OKbVUa11pbKyYgARBEALw5ptv0r17d0499VTy8/O57bbbrBYppogJyGrE34og2JZRo0bZvsYfDdICEARBSFJEAVhNNeqDEQTh2EIUgG0QU5AgCIlFFIBtkJaAIAiJxXIFoJRKVUotV0p9bbUsliCdwIJQiYEDB/LDDz9UCHvppZcYOXJkwHMGDBiAZ5j4RRdd5NenzujRo3nhhReCXnvq1KmsW7eubP+xxx5jxowZEUjvHzu6jbZcAQB/BdZbLYRlSB+AIFRiyJAhTJkypULYlClTwvbH8+2331Z5MpWvAnjyyScZNGhQldKyO5YqAKVUK+Bi4C0r5bAH0hIQBA9XX30133zzTdniLzk5OezatYuzzz6bkSNHkp2dzamnnsrjjz/u9/w2bdqwf/9+AMaOHUuHDh0466yzylxGgzHG/7TTTqNbt25cddVVFBUVsWDBAqZNm8Z9991H9+7d2bJlC8OHD+fTTz8FjBm/PXr0oEuXLowYMYLi4uKy6z3++OP07NmTLl26sGHDhrDv1Uq30VbPA3gJuB+oFyiCUupW4FaAE044ITFSWYK0BASb8t0/Yc/q2KbZvAtc+EzAw40bN6Z379589913DB48mClTpnDttdeilGLs2LE0btwYl8vFOeecw6pVq+jatavfdJYuXcqUKVNYsWIFTqeTnj170qtXLwCuvPJKbrnlFgAeeeQR3n77be6++24uu+wyLrnkEq6++uoKaTkcDoYPH87MmTPp0KEDf/7zn3n99de59957AWjatCnLli3jtdde44UXXuCtt0LXa612G21ZC0ApdQmwT2u9NFg8rfV4rXW21jo7MzMz+gvvXApbZ0efTqyQPgBB8Iu3Gcjb/PPxxx/Ts2dPevTowdq1ayuYa3yZN28eV1xxBbVr16Z+/fpcdtllZcfWrFnD2WefTZcuXZg8eXJAd9IeNm7cSFZWFh06dABg2LBhzJ07t+z4lVdeCUCvXr3KHMiFwmq30Va2APoClymlLgIygPpKqfe11jfG9apv/snYjrbJEozSByDYnSA19XgyePBgRo0axbJlyygqKqJXr15s27aNF154gcWLF9OoUSOGDx+Ow+GoUvrDhw9n6tSpdOvWjYkTJzJ79uyo5PW4lI6FO+lEuY22rAWgtX5Qa91Ka90GuB74Ke6Fv62RloAgeFO3bl0GDhzIiBEjymr/BQUF1KlThwYNGrB3716+++67oGn069ePqVOncvToUQoLC/nqq6/KjhUWFtKiRQtKS0uZPHlyWXi9evUoLCyslNbJJ59MTk4OmzdvBmDSpEn0798/qnu02m201X0AgiAIARkyZAhXXHFFmSmoW7du9OjRg44dO9K6dWv69u0b9PyePXty3XXX0a1bN5o1a1bBpfNTTz1Fnz59yMzMpE+fPmWF/vXXX88tt9zCuHHjyjp/ATIyMnjnnXe45pprcDqdnHbaadx+++0R3Y/d3EYnnzvo0Q3MrU1MQOIOWrAh4g66+iLuoAVBEISQiAKwDdIHIAhCYhEFIAiCX6qTeVgwiPSdiQIQBKESGRkZ5OXliRKoRmitycvLIyMjI+xzZBSQIAiVaNWqFTt27CA3N9dqUYQIyMjIqDDKKBSiAARBqER6ejpZWVlWiyHEGTEBCYIgJCmiAARBEJIUUQCCIAhJiigAQRCEJEUUgCAIQpIiCkAQBCFJEQVgOTLRRhAEaxAFIAiCkKSIArAccQInCII1iAIQBEFIUkQBWI70AQiCYA2iAOyCElOQIAiJRRSAXRC3u4IgJBhRAJYjNX9BEKxBFIDlSM1fEARrEAVgF6QPQBCEBCMKwC5IH4AgCAlGFIDlSM1fEARrEAVgOVLzFwTBGkQB2AXpAxAEIcGIAhAEQUhSRAHYBekEFgQhwVimAJRSrZVSs5RS65RSa5VSf7VKFkEQhGQkzcJrO4G/a62XKaXqAUuVUj9qrddZKJN1SB+AIAgJxrIWgNZ6t9Z6mfm/EFgPtLRKHkEQhGTDFn0ASqk2QA/gVz/HblVKLVFKLcnNzU24bIIgCMcqlisApVRd4DPgXq11ge9xrfV4rXW21jo7MzMz8QIKgiAco1iqAJRS6RiF/2St9edWyiIIgpBsWDkKSAFvA+u11i9aJYcgCEKyYmULoC/wf8CflFIrzN9FFsojCIKQVFg2DFRrPR/xhCYIgmAZlncCC4IgCNYgCkAQBCFJEQUgCIKQpIgCsBrxAScIgkWIAhAEQUhSRAFYjYyDEgTBIkQBCIIgJCmiAKxG+gAEQbAIUQCCIAhJiigAq5E+gORGa5j/EhTutVoSIQkRBSAIVrJ3Dcx4HD4dYbUkQhIiCsBqpA8guXE7jW1JobVyCEmJKADbILYgQRASiygA2yBNAUEQEosoAKuRir8gCBYhCsBqpOIvCIJFiAKwDdIUEAQhsYgCEARBSFJEAdgGsQUJgpBYRAEIgiAkKaIAbIP0AQiCkFhEAQiCICQpogBsg/QBCIKQWEQBCIIgJCmiAGyD9AEIgpBYRAEIgiAkKaIABEEQkhRRAIIgCEmKpQpAKXWBUmqjUmqzUuqfVsoiCIKQbFimAJRSqcCrwIVAJ2CIUqqTVfIIgiAkG2EpAKVUHaVUivm/g1LqMqVUepTX7g1s1lpv1VqXAFOAwVGmKQiCIIRJuC2AuUCGUqolMB34P2BilNduCWz32t9hhlVAKXWrUmqJUmpJbm5ulJe0IzIBTBAEawhXASitdRFwJfCa1voa4NT4iVWO1nq81jpba52dmZmZiEsKgiAkBWErAKXUGcBQ4BszLDXKa+8EWnvttzLDkgyZACYIgjWEqwDuBR4EvtBar1VKtQVmRXntxUB7pVSWUqoGcD0wLco0BSE4R/bDgW1WSyEItiAtnEha6znAHACzM3i/1vqeaC6stXYqpe4CfsBoTUzQWq+NJs3qifQBJJQXO4GrGEbnWy2JkIxoDYf3Qr3mVksChD8K6AOlVH2lVB1gDbBOKXVftBfXWn+rte6gtW6ntR4bbXqCEBJXsdUSCMnMisnw75Nh51KrJQHCNwF10loXAJcD3wFZGCOBhKiRPgBBSBpy5hvbfRuslcMkXAWQbo77vxyYprUuRWwXgiAIEWKvCl+4CuB/QA5QB5irlDoRKIiXUMmF6FFBEKwh3E7gccA4r6DflVID4yNSkqLsVTMQBOHYJ9xO4AZKqRc9M3KVUv/GaA0IsUJLS0AQkgd7fO/hmoAmAIXAteavAHgnXkIlF1LzF4SkwWYt/bBMQEA7rfVVXvtPKKVWxEGeJMQeNQFBEGKMswSK8qB+i8rHbNLiD7cFcFQpdZZnRynVFzgaH5GSFJvVDARBiJIvboUXO4Lb5RVor+883BbA7cB7SqkG5v5BYFh8RBIEQTgGWP+VsdVuKrtOq0YtAK31Sq11N6Ar0FVr3QP4U1wlO9Y4eij4cZs0CQVBiCOeBoBNvveIVgTTWheYM4IB/hYHeY5NVn8Kz54Iu5ZbLYkgWMfG72HCheB2Wy2JYBLNkpD2MmbZma2m49Q9qwPHkT4A4Vjnk2HwxwJwOqyWRDCJRgHYow0jCMcCNjEJxBep5NjtGQTtBFZKFeK/oFdArbhIlKwkRQEgCJB0dUe/37Y9nkFQBaC1rpcoQY5p7PGuBTuTDCbAZLhHb/wV/DZ7BtGYgIRYYrOMISSYZGoBJtO9An5rgDZ5BqIAEoGU7YJA0n0InkpdhcLeXs8gKRTA6GlrOf1fM60TwB7KXrAz0gIULCApFIBbaxxOV+iIgmAVNjEJJIZkulew8/0mhQJIUQq3274vQRCSAr8mkWTFHs8geRSALZ63NPOFACSVCcgWH2Pi8FZ4NnvPSaEAUlMMM5D12EEGwZbYIn/GG2kBlGGTZ5AUCiBFKVz2aAJUxiYZQRDiTlntN9nyvIwCspSUFGWTFoC9Xr5gI2xmGogP0gIoxx7PICkUQKpt+gDsPzNQsIhkKhST6V7B1vebFAogRWFfE5AgJAtldZ0k+RZtXPB7SA4FkGLkPG35C/FT27dcJgGAVR/D7wusu34ytQSTLs/bdxRQuEtCVmtSzIfucmuLbjjZMnw15PNbjO3ofGuun1SFYjLdawBs8r4taQEopZ5XSm1QSq1SSn2hlGoYz+ulmi0Al00eegVsViMQhPgRohPYfYzO1hdfQJX4Eeiste4K/AY8GM+LnXjwF0akfmeh0rXXSxdsSFJVBPx8iPs3wZONYe0XiRcnkdjsPVuiALTW07XWTnN3IdAqntfLypvDXWlfWNgR7Oe62xfB6Aawb13ixRHshx1bp7EmmCuI3SuN7bppiZMnYYg76GCMAL4LdFApdatSaolSaklubm6VLqBVGqm4bTIXwMRT0ylbKN5eNQNBiB/BvkMbfaPRUg18H8WtT1QpNQNo7ufQw1rrL804DwNOYHKgdLTW44HxANnZ2VV7kimppOLG5a7S2TEgnMLdvplESAA2Mw3EhyAFYlLcv/2ImwLQWg8KdlwpNRy4BDhHx3t8pkohFTclsbjM0omQ1Q8at43gJCnchRDE+hMoPQop6ZBqx4F+Qe7VxrXlqiOdwBVQSl0A3A9cprUuivsFU9JIiYUJyOWEr/4Kb58fG7nsgNaw8iModVgtiRBLxjaHj260Wgr/+P0O7VUwxh97KDqr+gBeAeoBPyqlViil3ojnxbRKJQ1XDNYEMM8/eiBqmSqToA/AUQDO4vL9zTPhi1th5pOJub7gn3iYQH4L2LVmDWE5g7NHwRhTbOwO2pL2odb6pIReMCWVVKWtXxSmwsu3KCM80xqO7wm3zjL2HYeMbeHu2KR/eJ+hYBq2jk16ycIxafrwxdMH4Kczrhp0mEZMsHuxyX3a0UAYe1JSAXBFO9Ek2pdW4XzftBKYIXYt8xMYo+u/0N7YWjWjVrAvQQt5e9WM44e97tMOw0DjjzIUgNtZWh52OBd+/V+Ehbo9tHZMORZrXtURm5kG4kuSmYBsTFK0AJTZAtBuZ3ngZyNg21yjdbDyI7jpW0hNj7MgwT5yqwqAZF2kw2YkhQIOYxjosfgcbHxPSaEASDFu0+XyUgBHDxrbb/5ubA/9AU3aBU8npi/SJjW+pKp5CvYl2fKhPZRCcpiAPC0AbwVgmoUiI54vzeIMEetaSlE8RkodA0y7B+Y+Xzk8mRRxomrEEy8xzLyWY99RQEmlANxud6WwMsJ5MTHNuPaoAcSN1/taLYE9WfYu/DSmcriNzQQxI9gw0HgUjDnz4Lv7Y59uLLDJ+04KBaCUYQJyu7w6gZXvrcfRXUNYL/sY6wMo3BXb9IRjh2CjgGxSMMaUUO6gC/caPwtIjj6AVE8nsNcwUF8FkPAWgE2agsdy51t1wmamgfggAw7K8XoG/+5gbC0YOp0ULQCPvV+7giiAeBbItv64Tdk2fA3OEmtFSWaSSQEHdQZ3LD4H6QOwFGW2ANzBOoHDejHxNAFFwYoPjbUFou14zdsUG3kEwR9BC/kEtkQLYjTrPRTVoHWdFAqAsj4AbwXgW+BHaQI6egjmPGc4jEs0v75ubA/9Hvm53s/Bxhk1YRQftua6NqsZxhUr89nqT+HFjpDzc/yvVQ1cQSSFAkgzWwDOCgqgCn0AwVoAX94Js8bCjkWVj9n64/aWLY6Z0lkMub/FL/1Y8XyIuSDxwiYFQnyxgTO47b8a271r4nudCog7aEtJTa8BQGlpkFFA4XyAweIc3uc/3XDTjoZo0k+Ucpp2N7x6WvkEPLviFLfYcaPMJGIOx96/GZa/73MsGRQh2KWvIykUQHqaYQIKrgDCWS4syEuzRS0/zjLk74CnmsHeKqxjvG2usS2J//IPlvLb9Kq51rZF/kkQnkL+jbOMljNwTI8QsrE76ORQAOmmAvB2Buc7ESxRGW/vOsP3kG2IoA9g/dfgKoal70R+GU/awT6ABa8YndmlRyNP3y58cA3M+3fk5yVFzdenkHd6vWebFYxxxybvOykUQFqaaQIq8VIAm6ZXjBStCSgsFLx+hrEAS7XEc/9V+Fg9LSx/JjIPv7xqbI/sjzz96opNCoKI0brqq8iF2zmqddVam7bDvu84KRRAeg3Dy6cz6Dh3mw7xDIsqyrDpR9izOvx0wqnFBz7Z3AY5N72Wsa3OLYCqUt1qwPNegLHHRdanE84wUO9jSyYYFaatc6oo5DGCs8QYuuq9kl+MSA4FkFEXAF0cxP5clRZA7kZ4oqFh9w10/uK3YOUH4QkaLZEWIpOvhtn/iuCEaFoAHuURJMvVqG1sS4/xfgJ/2KIiEQErpxjbw7mRnxt0IpgXe1YZ2wNbIr+GnYj23e5eaQxd3TYvNvJ4kRwKoHZ9409JGGO813xm2Lr94vMid5sZdOWHXoE+GdnjbvpYIJoWQJkJKMi5KeZ6DG4L5lJYRjUr+MuoSoslQAuguim/mBDBPYfz7VSR5FAAGfWMP8EUgOchfzoCPhoaII7PS6vV0Nh61tU1IoUnlM/L/MenK5kwf5uxM/8lwzyTaEJ+iFG0ADznJuXHHgax+riPHoyLqSCmVFoNVRPTmcD7NoROJ6H5MMpRQNp0YROs9VxFkkIBqJqGCeiUPdMCR/KXIUod5bV8IxIAbhSb9hZCqtG5jKs08nHMfuK9/6s5k3fG44Z5JlwSlZejagF4hKymCiB/pzGLNF7EqkB6tg28e2ls0gJj6O8TjX36iqKlkgbwqlNE+Ry2zoHX+sDSiQEi2GS4abjv+5kT4at7jf+VRi5GT1IoAGrUAaDN4eVBIvl5IV+Pgv+dDYV7KgS7XG7O/c/cco1cYQ5B1TOWyx3k3L3rYKe/xdy98VMwFxfC+q+qLFMFivKqfq6OsgVw6I+qXzsWvHsJfPaXqo98SSSe2a6xYON3Rg00YIEawfssK3vjaALK22xsd68MIIMFne2h3EF7c8TnG3Mcgv0bzVOlBVA10mvjDvXgHQWVwzxuHTzHfDOqPwUQbmb2yYhurXC6gpz7+hnw5sDw0vbmy7vgoxuNDuuQhJD955eMbVSjgKrQ2b51DrzUBVZ9UoXrxogCz/oGMa452r1BFCg/R1WQ+mkBxMoE5JErd0N06USDs9hw0Bipy4uVH8HzbQNX9EQBVBGlOKIzgseZdre/E332fRWAz9R2f3HCxEUK7kgzv9ahZ9YeNPsVfEfWzIpk9I8vUZiAwhpt5TMre585FnzHIljxQXCHe4e2w5ZZkcsnhCCCd/7ZLfDB9YHT8NcC8DdEtErKwEznj1+qcG6UuN2QM99Y8W3q7V75OMz72GYOd90XYO5DHBRAciwIA7hT0oK/h8N7ghw0CdR01W6v1kAwh3F3BJaPFJzBTEAeDmyFei1gbHPI7GjUdGo1CiJzgAlYc54Nfa1ARDMKKKyPwStO4d5yfzHL3oNF4w2312fe5f/UV/tA6RFLFtewlBUfQtMOcUi4CoXw6o/9hwecBxDqGnEw2+z/zchHtRtXPY3NM2HrbDjvKWN/4Wsw/WGo5ZNmFP2CFajSOubBSY4WANBAFwaPcPQg/PZDiFSMF5SuXJyqcsr2q9QC8BmR5CYlYB/Amp1ehdnKj8pt8Z5mrmcyjr+CuSxTxXLFsziPAvJ+nh8NLffc6HHUVuQzU9jlhA3fmLNTj1RBtgiI+eiRGKU39XZ460+xScsfgZR+RM/DX4vZJ41YmYBCsWSC4YsIYPlkwwWJPzNwMN6/EhaMK9/32OqPBlmXIxrTmZiA4oynt92XdV/CnjUVMuc3NR8qz8hV6QPw6VTTBO4ELhseCkbzMJKPJJwJWP7Yswb+MDsT92+ChW+UH1MKtvwUme/8sEYB+VESh/2tlerzET3VBKbc4DMfI17Y3WgfJ2Kp+Cql5dUHEOnz/XmcUXiXrfcdQQFbsNPYegpxz35VCehQ0s89hTsZLpLjVUAUQBBKXOYLnTUG3uhbOYLnJRZ7tS7C8ipaGQW4/SkArWl31Gso6vogQ1l92Tob9q01LxDhegdv9IUJ5xn/J5wP3z9QfqxgF0y6Ar64LXxZypRlFfoAwmXqyKqdFw4euZ3FRoGzZEL8ruXhyH5D8dpy7kQVCqNAJqBo7m/uC8a25IjPNWKEqxS81xIPRlj3EUS+UK7Ij7UWgFLq70oprZRqaqUcHhyl5Z2LR0tc/HHA1yeNb8Y1C6q8zV5KoOqZ2W8fwLqp3Jnjr4PaD66SipOAPrmp/H80mce3pu/52PZHssBLJPMA7FjgmUy5wdj+NDY26QUrND672VC8e9fG5loedq+C59pVduOwf5PRkemPWBasflsAgY75HPel0kCMGCuAp5rCxIvDixuo4uIsgU0zfCNXjrfms+DpH0vzAJRSrYHzgMQM8P5L6Jm1h46Wewstq/17EyzjehRAFLUZl1tX/gAP5oSfwJt/gjHNyvcrfLRRfBgpPmMFopkIFguvqzEojOb8lsvyPw6GjvjHQlg2qfya0Ywu2b44svgeW7K7NHi8SFkwzuhH2eo1WmrvWnglG+b7uLL2vItF4w2zX6TsXlm+FkR5on6uEaFJJH8HLHqz8gTMaPLG+AH+R8eF+84D5dvpj8Dkq2Dn0ugWvjnGRgH9B7gf+DIhV2vdO6Lo/vNRgBYAeL2cKBSA1pX94PjLKDpEk/SD6yCtZsWJW+FknkCiV6p5hPmR/b4ATjjDeJhlhVgcTUARMGyCMccj55kQtbsJ5xvbtADDiLfMguM6Q93M4OkUF8Lbg8r3S46UTVC0Bfk7jO12P0uaeljwCrTz7WgO8T7/18/Yjs4n8Fh/HXmBOPnacvNmBTmiUABOhzE6buBDVTs/UL71TE4rCtI5HA7HiglIKTUY2Km1DjBdr0LcW5VSS5RSS3Jzq+B5MAKaq/IaoXZDhvJxH+2TSbW/lX6qWP6/WmMcHfU2H79CAZj3YvDjv31vdFxHTADhfRVAmZkpxMf2zoWw6iOY/YzXJSI1Afm7hgWzOf3ZgbWGSZcbs4RD4TuDuGwYbpDnEYvhg3tWB3bZHPG78JPfq0SQPoBw79l3pI3bZYziKY5wJM+y96Kb4V6BAAMuPN5Mox7hVI1MQEqpGUqpNX5+g4GHgMfCSUdrPV5rna21zs7MDFHLiiV5m2ilfBcmqfgCXS6vQsF3nPu6aRH7Mf+m5kPwQvuKgf4+tLyquMcNI/MFnIHok/E2hRou68WBrTD76cjkCNUCmPcCvHtZ+DL44b30pzlZhbA+ersA8WeG2fitsQ1n1qnvPZU6jOGH3nbfL++CN84OnZYvi94MfGzlFMM/0OpPjaGy43qUtzK/uNW4JlTdNBdJoRbQ/BHABBQJ2gXPtIbv/xnZedPuhiN+KpbFhUbejUiGEIseHcyB+f8JnU7ZMpk+VCcTkNZ6kL9wpVQXIAtYqYwM0QpYppTqrbUOYzZWYkjZtTRkHKfLXfYADxwppjGUZ+6P/y82gkTaKRYwnTDMKt8/AH38rFbm2wcQET4KzPt+fpsODVrCcaf6xAm4U862yJSrL/1SV1NTTQSCjBz698nBE/F0CIeD7/NXqvLEwOWTwk/Pm81B+rc8PvW3zjLmuRzJhYYnVLxmlwgcD1aiKgW3nxaADnAsXMIdqRMu714Ku5ZHdk6ojujv7vOOHLlMx8IwUK31aq11M611G611G2AH0DMhhf8N4fuScQedVGXgdJZnusal5nj1BNivq3QNHYad1eOPv1J4FArA33PcPMMYgfLBNfD6mZWPe99frJzA/f6LMXzT+zLxNCVtnllxv9I7i+TafuIe2GasNRGy4AvDNPneYGOoc0iibAEE6wOoUnreSQR5Dof3wdOtYdeK8NPzLfz3bypfsjSgDBHOuSl1lA9jDYdjpQ/AMjqch/OOJWFF1drfB1oxc6rt/kYHxHjCTBiKKCwCrXHgTaofBbD+KyjY4T++r2x+m8w+cdwueP+q4Hbz3A1VW1g9GH4Wsnf7fccxIneDca9LJhhjyX0LqMVvBT+/uLC89u6Pz2420ghVSw13cEI47p79ebWsUoXHR5ZSR/AZ3PP8mE18Z7hPuiLw+ZtnGn0DC1+LSMoKvJINPzwEB38PHCecda89LPivYSX46anwZYjDMFDLfQGZrYCEkdasPdvdmbROycVNCin4z8Dpu/wM2fMpeOss8VMjiOWknYC1uypc48DWMFoAqYadso5XX8tHN4ZO21FguCD2l0F9lYSnIAzmnfTHR43t6QFsoeEQSHl6EdJDbPALVNxd9QnUrFe+v/htY43jr0cZz6fTYJ+LBxnauWMJzH0+TDHcBG1NeAqj1Z9ARoPA8QKmH6ATOGhYqDR99l/qEnyUWP4fxnDSFt0qH1MpRp4Ky14fA4UfTOFFogAc+bBpemTXrk59AHZm0dkTeGf2xzyWHtjmWmdl5RojOfPDSD2GCsDlfxH7bbkFZFUpwRCyte4DL3eDrH7hJZe7wWghLJsUuGPYt4PyTc8wwmjNCSGopAAqf/xuUnC7NSkpMSgYPr+54v6BLbDfM/wvLzIb9VvnQIPWweN4lG24NXBXSeVaczBKHcai743bBY8XSQsg0Exgb2XonQf2ennF/F8/uOl7aNmzfFilJ82Q2SaG+SpQi9w7PA4FdbzSTS4TkMlV5/bjsbGvRH7iV/eEjDJ/c27VFsr2h8v/0n5ZjvVVSy9UAZvV39hWmrgTmILFH1K6ZXbgCEf2VdyPZMH3aPpTfnzUWFxjzvPG5Do/H24d5cDhdBmjcbwZ3QByI5nlHICFZgtRuyNf57hG3cDHDm0vt2e7XcFHZVW47zAKwk3TjZFJnhq194Ls/vLPL6+Fto2XC2Nsvvmbn5mxJtsXGtuiA+XrcXjI3w5f/83oN/LrIyoAHrlXTQnP4Vs4o+yOeI0QdJUY7yGOa/ca6UoLwPYsXTiHs7qeEpvEXjnN/xC1eBFA4QSj/tZv4iCISagZsEsmQNMAI3V+ecUwZ234Glqf5jdKr5RNHNq2gNr+3HS/6v+cKuFvgl8o0moGPvZSZ6+0QyhJv4VGCEUw619wxf9CpGsWcqs/Nn5Z/aF55/DOOfSHMTM2GN7+tbwpm5Vr3kOkrcaVH4SO897gIAfNe3i5e3nQmGbQ5uxypR0DBXDwcDE9xswgx3v+YXWaB1At6HQ5AEVZ58csyb+mfR6ztGJe+H/ob5EOL6xaTPzQdvOPz8ccasLb16Ng4kWBj3smBblKCWT2qPfFn8MSMSrWTa1cmw2Fb3/KL6/Bk00rL3ZTFQXgCqFY3U6Y+UTl8GCF7Rt9K7eaolqK1M+1ivIqtkjCJVJXGsFaCZ7CvcRHQeXMi6wPIARb9/vxtCsmoBhz7bswOp/a7fwMRYyGtTFUArEk2HhxCO2NMF54FJNvYZYzL7p0Azk28yLVEWCWbCwp2Gkoq0jw/tiVgh8eNAoy39E6W2eHSqhy0O8/Bz/lYI5/M+Dv8w3zprdrcG98zTKVBhBEUDP2p2wineTlIRK35QDFVVxMyJN/A828joAUdzHDU7+vGBgH05KYgACyb8K1czlq9wpSDuVEn96vAT4Qu1O2ILUiph1nodi7xvDr7lu47Qw9GS8Ybu0yajhhjAiynFIfz7OBmvu+w0nnh2glxfq+P785iNIJkmfCHdUUTlpVihcjgra4YifLcWveZHT6exUDpQUQJzIakHrdu6TUb2G1JNaywlx6MaqZv1XEM/QzhmzbF72L7oSRt6nivrd/Gm/X05F2jMfMz43JkSDplTqMSVf++GlMZCbNmK6BEMO0NnwL/+0V4DKxmwSa5q9leiy5g7Yl542BZqfCQ7vKgnbesYXxzsoeI7d3DdNHf3UkDhnNCg4VGX0aLrc79jO0Y12w+uKtELxH+Tj9Dw0OyPZfYyNPGWZh6m/W+AfXVPZl5U24tvjJ10bu1C0YsXQT8cODFYehehPDPKb8zU+SFkCcaZUNdyww3PT++Uv4y4+0bNaUW+97nsLWA8mlfPH1kg6XwnWTKWrWg8ODnrNQ6DiQCHcWCaBXilGIOl3uBC0XmQDmPBM6TiAcVbRte+NxzVGVNQrCvf6mHwzf/OEQTl4N5T49RrjC6HMKG3/3JQoggbQdUL6GQIOW1PvLVJr2LPdA2bZ1KzjlEmrfMZu6Z4ywRsZ4EWACWnUl/Yf7rRbBHkQ6FNUfsayZJ4pYO4oLQMEfYbjTCBPld81gMQFZijp/LAx8BP66EtWgZfmB1HS4/A047ebAJ8eQPReG8CMjVCAlkC8jITko2BU6Tgxo5I7diLKmG96vHCgtAIupWQ/63weN2lQ+1n0IXPxv6DUcgP3njiPb8Tp/K7m9QrShJQ9GJcKCc6eiO4axAIkgCAZ+HAFWS0QBVAMufRlG59O07zCWPHMDd937MOO7f8ZuZThYK9bp7NBNAdjiNkYd3VNyF+85zw2Z9K/ujrQ4uTcZaeVNwZedV1aKN7o0AZObBEFILMfCegDJRttm9bn18kG0uPN76DaEf919E+/1mILrH1v5/dofubTBZ0xzn8k7rgsAyNe1AfhryR0MKn6OPdroeO7qGE/XRxaQ1bQODWql080xnknOQbzhvIROjgksdJe7n5jouoC7S+4KKpejWff43LAgCPEhDgpA6ZiOt40v2dnZesmS8Pz5Vye01sz+LZf+7RpRWlLEpulv0bDf7Zz13GwyOchJKbtYkdqVdU+ej/LKBEPfWsjPmwMPRxyYspx3avifgHO6479Muq4N7b+8NOb3IwhCHBhd9VFcSqmlWuvsSuGiAOyLy62Zv3k//do3rVDwe3C7NRpITVF8u3o3d0z2v6bv+SmLOEwt7k6byukphifRTo4JFJHBlBpPlYX1dbzMzxl/DSrTHFdX+qcGWajEpKfjDf6vWz1GbQxjIRqLeKfDa9z0mx9HcMKxz7WTYrZsq67XAlW4OyZpBaRpB7jLzxolYRJIAYgJyMakpij6d8j0W/gDpKQoUk1f9hd1acG2py9i/ZMXlB2vmWa83h/cvel89mBuLvk7o0v/TBvHZIow3AzeUPIw15c8wtCSB9lJJm0ck7m55O+0c0yih+MNzit+tsI106g8pO5D50BGllRUHAeoz42XnMtSd+WJQWNKh9LNMT7s5/BEaYzWV/Zhe70eAY/5dt4L1Z8j2vSw+qdHIC0jeGRvrvQ/6m6R2/BE67gsRF7udz88vAdqlC8Y9FxjP872gjEsGsd6gRFfQMcQSilq1UhlwT+NRVeOb1gLrTVubSiT8zodx4T57WB1eW3FTQoL3Z28U2GG25jqfpD6HNT1aeP4gKtT5zAk9Scedd5EM9chHk97j49cA3jXdR6aFJpTboryKI3MejVpMnoxwx/5F1t1C6bWeJTdugnvuwbhoNzd8QJXJ85MNRb/+FfpEB5K/5DejlcppBZHTUW1SbdCAyvcJ7E24y8Bn0GBrkV9Ve5X5zvXaVyYWrnmtNjdgRQFHwycT+mPTzAsrdxR3kTnecx1+1l9qhpwILUpjfQhVKAx/6PWwn9OLdvd1e95jp97n/+4tiBMv1QXPAvfP2D8H/qZX3fTZxS/wuXH7eXJs+4IvhpX5ilQrzlsNT2vdr0G6jSFSZdXiFYDYzKcO7VGWVjpHUt4+uWXjcWm6rWAu5dBDaNfj4d2lK1L/dqu9lxdozltU8yl0C98Hor2w5xn4YrxLKk/iOx323o9hvjU1aUFcAxyfMNaHN+wFmAoBU8rodeJjXl1aE+2PX0R00f14+1h5S3CH0f144Ob+zByQDvuOac9rRrVqpDmp67+XFXyBFv18Sx0d+LCkmeY6LoAbWahaQ9dywOlt9Db8Sq/6fLVrFJSFG888U/+ft359Cwez8UlT5cV/v8qHcIadxtuKH2E3o5X6V/8IuNdl3Cq42320ais8AeY7+7Cz+4uHKEW/Ytf5M6Se3i0dDgdHO/SxVFeQ+tZ/D++cfXmJeeVnOZ4jZGlozjV8XZZ7e9jZ3/+VTqEa0pGoxRcmH0yLzqvYbduzODiJ2njmMxo53D204APnAPL0u3u+B/PlBpeS793ncYqdxY57uP4u09L4Z6Su+jqeJOTHD6OvHy4reReOjkmsMJtrLh1VNcIGv/q4seCHi+7/yPj+Pa42wCY56ron/9I0668tLgId5rxbjs5JnDm9JaV0gCgfxU9b3qT6rWmwW3zjEKsURaXFZevgzuk5GFubvg2PLyHfrW+KAt3NTKey77BFf33F13ts3gPwO0/w+m3Gy5cHsmF9oPgsooLPjkankQBdXhvb1u25h31Ozls79VfGn9q1oMbPjYUQYMTjDDP0O/6reCWWbzY43t+cRuKdM6u8nq0q1FbJrgupI3jAw7ftaa88Pcw7Gt+u8FY9Eab3lGdI3/lq4xL0AMeNOz83a7DjWJA8b9ZhKms4zAJDKQPIOnZk++gfq00atfw3xj8cNEfPPj5am4+K4surRrQO6sxZzz9U4U4Yy7vzI2nn8jb87cx57dcLu3aghYNanFW+6YV4q3ekc+lr4SzrCbM+scA/jhQxLAJ4fnR76U2coi6bNH+C7SxaW8zNG0mHRzvUoLhx2ZE3yweu7QTM9btZVHOAdxuTUZ6Kq/MMny91KSEPinrK7QGrkyZywx3LwqoUyH94zhAGi52Ur6eciuVS7bayI/uXtSjiNYql8aqgN26Cau0UcCl4mJI6k/85OrBgox7eKr0Rua5u3BD6kx+cZ9Kj5TNDExZztUlo1mdcTPr3a1Z7j6Jcc4rOUB9xqa9zc/uzrRL2cVUV1+26JaMTJ3GA+lTeNN5EbekfUuO+zguLvkXRdREk8K5KUu4K20ql5c8iSaFE9Q+atVrzJDavzL80Ku86byIzje9ws1vzqKRKqRIZ/BA2hQedw7j8cw5DCmc6PcZLzjzLX7eXoLeOpv3XYPIqNeEj69vSZvMhhRlZNLvuVncd/7JPPDZavqo9aQod1kh+u6I3tw+aSnnuOazVrfhkZpTOIfFDCl5mDRcbNPN2aGbkYqLz0/4nB2ZZ3PWab2od0K3siU9nS43Y75ZzxU9WtKtZX34+l44aRB8/H/83rgv/XeVrzGd89gZ8FwW690nMN/dmYnO8znphJa8m/8XuP79Csui5uw/Qo20FI4v3gaZHcl3uOj25HRScXEcB9lFU3IybgDg4W7zmfyr4S5j3v0Dad3YUABaa3LyishqWoeNewo5/6W5XJ06hxfS/2dUUKjFKzf04Oz2meQWOth/uITrxy+kFg5OVTm89uCdNKsfgdnKB+kEFqqE262ZuWEfg05pVqEvwu3WKEXA/olA7D9czE/r97GnwEGXVg3oeUIjRk9bS5+sxtRIS+GBz1ZR6tLkPGM44PvPj78xc8Ne1uwsYMLwbB6dupbLuh9Pj9YNuXVSZXfRvds0ZlHOgQph/x3Sg3s/XEJdjpJP+VKLV/ZoyYvXda90vweLSli54xCPTl3LzkM+bprjSF2KOEwtAvnN75uymlXudhRS2+9xD83J4+MaT3JD6cOcoPaxxX08e2kclgwtyGM3TYLGyVK7GVJ/FZMLulGXoxRSmy5qG9+4T68ct2kdaqalsGFPgBW+AtCYAv4v9UfGua4oa2X64/gGGewrLOaCzs1p3bg2r8/eQpM6NXjs0k4M7t6SDXsK+HXqq7yY07bCu//67rO45L8VKyPdWjXgy7vOqnSNNv80Vr0bc3ln/jhQxJ58B9NWVpxdfEfqVBqrQsY4y/urHrukE+edehz1aqYzfd0e7vt0FR/ecjpN6tbgvP9UXm/hroEnMWP9XjbsKeSDW/pww5vljvxu69eWm/pm0bxB1ZSAKAChWuBya4qdroAtEg9aa/49/Tcu6Nyczi0b8OWKnTz3/UZm/K0/GekpON2aRdsO0L5ZXZrVz+BoiQu31tz0zmK25B5mYMdmjBzQjnaZQdbeBX7dmsesjbmkKHht9hYGnXIcb/65F1+t2s19n6yk2Bm9A7ATm9Tm97wI1koWwuLCzs35bs2eiM556KKO1K2ZztTlO7mhzwmMm7mJrfuPRC3LuZ2O48d1e7moS3PuHHgSF48L3hJ++fru/HXKigph747oTf8Omf5PCIEoAEGIkhKnm/RUVdbqKXG62VfooFWj2izOOcD0tXsYdW4HSl2aFdsP8ceBIs7p2Iwf1+3l8WlrK6SV88zFrNtVQNvMOqSnprBqxyF+2ZrHij8OMX1dBAue+6FmWgpD+5zIhJ+3RZWOEB9qpKZQ4oq84vD5HWfS84RGoSP6QRSAIFjIwSMlNKydztpdBXRsXo+01MBmjX2FDjbvO8yZ7Zri/X0+9fV6Oraox7XZrXl5xiYOF5dyfMNafLVyF3ef057JC//g5OZ1ue/8jgDsLXCw69BR6tdKp11mXZ78ah0Tft5G11YNcGtNu8y69GjdkNFfratw/WWPnkvPpyouH3rvoPa8NMNn0ZoY0LRuDY4UuzhaanTKXtGjJV8s3xnz61RXGtVO52CRMdpoxt/6cVKzeiHO8I8oAEEQAuIodZGRXnGkSYnTTY20FLTWKKUoKnEy6Zff+VPHZvyeV8SOg0UMO7NNWYvoxekbadesLn2ymrC3wEHrxrU5/6W55BYW88Rlp5J3uJj3Fv5O3ZppDDg5k1+3HuCDW04ns15N9hU6eG3WFh65+BRy8o7w2bKdvD67fAH490b0Zl9hMf/4ZGXQ+6hdI5WiEkOZ3HxWFm/ND94K6tKyAat3xmCdBB8+uvV0rhu/MGS8y7sfz9QVgb2VzrlvAP2fnw3AprEXkh6k4hAMUQCCICScEqcbt9aVlEs4bNt/BAW0aVqn0rFSl5u0FMUfB4poVKcGGWmprNmVT4sGGTSvn1GmlLTW/LIlj98PFNGlZQM6t2zAkWInt7y3hAVb8vhtzIUoBcVON5N++Z1vVu/inj+1Z8b6vXy8JDI34rP/MYDj6mewcFseA09uxrsLcvhk6XbW7PS/hsLXd59F55YNyNl/hAEvzPYbZ/2TF7Bi+yHyjhRzSdfjI5LHG1EAgiAIEbBpbyHN6mVQIy2FjHTDbr9w6wH6d8hk4s/byMqsG1an7NESFz9t2MdFXZqjlGLWhn3sP1zMNdmtK8SbsugPzjnlOBrXqcGanfk0rlOjbBhptIgCEARBSFJs5wtIKXW3UmqDUmqtUuoYW1RXEATB/ljiC0gpNRAYDHTTWhcrpZpZIYcgCEIyY1ULYCTwjNa6GEBrvc8iOQRBEJIWqxRAB+BspdSvSqk5SqnTAkVUSt2qlFqilFqSm5ubQBEFQRCObeJmAlJKzQCa+zn0sHndxsDpwGnAx0qpttpPj7TWejwwHoxO4HjJKwiCkGzETQForQcFOqaUGgl8bhb4i5RSbqApIFV8QRCEBGGVCWgqMBBAKdUBqAHst0gWQRCEpMSqFcEmABOUUmuAEmCYP/OPIAiCED+q1UQwpVQu8HsVT2+KPVsZIldkiFyRIXJFhl3lguhkO1FrXWnacrVSANGglFribyac1YhckSFyRYbIFRl2lQviI5usCSwIgpCkiAIQBEFIUpJJAYy3WoAAiFyRIXJFhsgVGXaVC+IgW9L0AQiCIAgVSaYWgCAIguCFKABBEIQkJSkUgFLqAqXURqXUZqXUPxN43dZKqVlKqXXmugd/NcNHK6V2KqVWmL+LvM550JRzo1Lq/DjLl6OUWm3KsMQMa6yU+lEptcncNjLDlVJqnCnbKqVUzzjJdLLXc1mhlCpQSt1rxTNTSk1QSu0zJyx6wiJ+PkqpYWb8TUqpYXGS63lzfY1VSqkvlFINzfA2SqmjXs/tDa9zepnvf7Mpu4qDXBG/t1h/rwHk+shLphyl1AozPJHPK1D5kLg8prU+pn9AKrAFaIvhcmIl0ClB124B9DT/1wN+AzoBo4F/+InfyZSvJpBlyp0aR/lygKY+Yc8B/zT//xN41vx/EfAdoDCc+P2aoHe3BzjRimcG9AN6Amuq+nwwnB5uNbeNzP+N4iDXeUCa+f9ZL7naeMfzSWeRKasyZb8wDnJF9N7i8b36k8vn+L+Bxyx4XoHKh4TlsWRoAfQGNmutt2qtS4ApGIvRxB2t9W6t9TLzfyGwHmgZ5JTBwBStdbHWehuwGUP+RDIYeNf8/y5wuVf4e9pgIdBQKdUizrKcA2zRWgeb/R23Z6a1ngsc8HO9SJ7P+cCPWusDWuuDwI/ABbGWS2s9XWvtNHcXAq2CpWHKVl9rvVAbpch7XvcSM7mCEOi9xfx7DSaXWYu/FvgwWBpxel6ByoeE5bFkUAAtge1e+zsIXgjHBaVUG6AH8KsZdJfZjJvgaeKReFk1MF0ptVQpdasZdpzWerf5fw9wnEWyAVxPxQ/TDs8s0udjxXMbgVFT9JCllFqujLU3zjbDWpqyJEKuSN5bop/X2cBerfUmr7CEPy+f8iFheSwZFIDlKKXqAp8B92qtC4DXgXZAd2A3RhPUCs7SWvcELgTuVEr18z5o1nQsGSeslKoBXAZ8YgbZ5ZmVYeXzCYRS6mHACUw2g3YDJ2itewB/Az5QStVPoEi2e28+DKFiJSPhz8tP+VBGvPNYMiiAnUBrr/1WZlhCUEqlY7zcyVrrzwG01nu11i6ttRt4k3KTRUJl1VrvNLf7gC9MOfZ6TDvm1rNcZ6Kf44XAMq31XlNGWzwzIn8+CZNPKTUcuAQYahYcmCaWPPP/Ugz7egdTBm8zUVzkqsJ7S+TzSgOuBD7ykjehz8tf+UAC81gyKIDFQHulVJZZq7wemJaIC5v2xbeB9VrrF73CvW3nVwCe0QnTgOuVUjWVUllAe4yOp3jIVkcpVc/zH6MTcY0pg2cUwTDgSy/Z/myORDgdyPdqpsaDCjUzOzwzr+tF8nx+AM5TSjUyzR/nmWExRSl1AXA/cJnWusgrPFMplWr+b4vxfLaashUopU438+mfve4llnJF+t4S+b0OAjZorctMO4l8XoHKBxKZx6Lpxa4uP4ze898wtPnDCbzuWRjNt1XACvN3ETAJWG2GTwNaeJ3zsCnnRqIcZRBCtrYYIyxWAms9zwVoAswENgEzgMZmuAJeNWVbDWTHUbY6QB7QwCss4c8MQwHtBkox7Kp/qcrzwbDJbzZ/N8VJrs0YdmBPPnvDjHuV+X5XAMuAS73SycYokLcAr2B6BoixXBG/t1h/r/7kMsMnArf7xE3k8wpUPiQsj4krCEEQhCQlGUxAgiAIgh9EAQiCICQpogAEQRCSFFEAgiAISYooAEEQhCRFFIAgAEopl6rohTRmXmOV4WFyTeiYgpBY0qwWQBBswlGtdXerhRCERCItAEEIgjJ8xT+nDD/wi5RSJ5nhbZRSP5lOzmYqpU4ww49Thj/+lebvTDOpVKXUm8rw+z5dKVXLjH+PMvzBr1JKTbHoNoUkRRSAIBjU8jEBXed1LF9r3QVj9udLZth/gXe11l0xHK+NM8PHAXO01t0wfNCvNcPbA69qrU8FDmHMOAXD33sPM53b43NrguAfmQksCIBS6rDWuq6f8BzgT1rrrabjrj1a6yZKqf0Ybg1KzfDdWuumSqlcoJXWutgrjTYY/trbm/sPAOla6zFKqe+Bw8BUYKrW+nCcb1UQypAWgCCERgf4HwnFXv9dlPe/XYzh36UnsNj0UCkICUEUgCCE5jqv7S/m/wUYnioBhgLzzP8zgZEASqlUpVSDQIkqpVKA1lrrWcADQAOgUitEEOKF1DYEwaCWMhcGN/lea+0ZCtpIKbUKoxY/xAy7G3hHKXUfkAvcZIb/FRivlPoLRk1/JIYnSn+kAu+bSkIB47TWh2J0P4IQEukDEIQgmH0A2Vrr/VbLIgixRkxAgiAISYq0AARBEJIUaQEIgiAkKaIABEEQkhRRAIIgCEmKKABBEIQkRRSAIAhCkvL/0EvYzHKGLxwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 7s 44ms/step - loss: -3.6558\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 8s 45ms/step - loss: -5.5533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.553305625915527"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from LSTMutils import MeanVarianceLogLikelyhoodLoss\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SequenceLength = 250\n",
    "validation_split = 0.1\n",
    "batch_size = 64\n",
    "NumEpochs = 2000\n",
    "\n",
    "df = pd.read_csv(r\"../TrainingData/SimulatedTrainingSet10000.csv\",sep=',',header=0)\n",
    "\n",
    "labels = df.iloc[:,0]\n",
    "df_data = df.iloc[:,1:]\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, test_size=validation_split, train_size=1-validation_split, random_state=42, shuffle=True, stratify=labels)\n",
    "\n",
    "# normalise time series data\n",
    "min_value, max_value = df_train.min().min(), df_train.max().max()\n",
    "df_norm_train = (df_train - min_value)/(max_value - min_value)\n",
    "df_norm_test = (df_test - min_value)/(max_value - min_value)\n",
    "df_norm_val = (df_val - min_value)/(max_value - min_value)\n",
    "    \n",
    "X_train = df_norm_train.iloc[:,:SequenceLength].values\n",
    "y_train = df_norm_train.iloc[:,SequenceLength-1].values\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "y_train = np.broadcast_to(y_train[:,None], (y_train.shape[0],SequenceLength))\n",
    "y_train = np.expand_dims(y_train, 2)\n",
    "\n",
    "X_val = df_norm_val.iloc[:,:SequenceLength].values\n",
    "y_val = df_norm_val.iloc[:,SequenceLength-1].values\n",
    "X_val = np.expand_dims(X_val, 2)\n",
    "y_val = np.broadcast_to(y_val[:,None], (y_val.shape[0],SequenceLength))\n",
    "y_val = np.expand_dims(y_val, 2)\n",
    "\n",
    "model = keras.models.Sequential([keras.layers.LSTM(50, input_shape=(SequenceLength,1), return_sequences=True, stateful=False)\n",
    "                                 , keras.layers.LSTM(200, return_sequences=True, stateful=False)\n",
    "                                 , keras.layers.LSTM(50, return_sequences=True, stateful=False)\n",
    "                                 , keras.layers.LSTM(10, return_sequences=True, stateful=False)\n",
    "                                 , keras.layers.LSTM(2, activation='softplus', return_sequences=True, stateful=False)])\n",
    "\n",
    "checkpoint_filepath = r\"../Models/SimulatedDataPretrainedModel\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss = MeanVarianceLogLikelyhoodLoss)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val,y_val), epochs=NumEpochs, callbacks=[model_checkpoint_callback,keras.callbacks.TerminateOnNaN()])\n",
    "\n",
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history['val_loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model.evaluate(X_train,y_train,batch_size=batch_size) #min loss shold be -6.908\n",
    "\n",
    "bestModel = keras.models.load_model(checkpoint_filepath, custom_objects={\"MeanVarianceLogLikelyhoodLoss\": MeanVarianceLogLikelyhoodLoss})\n",
    "bestModel.evaluate(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6252f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
